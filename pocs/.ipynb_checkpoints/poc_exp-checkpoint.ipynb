{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f3528a-8190-4f39-a8be-41f7fe248810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting owlready2\n",
      "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: owlready2\n",
      "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=23936649 sha256=0d81959a091bc145874a64f4efc8bbffdd41c891011a1a833ec53c56c4338e98\n",
      "  Stored in directory: /home/kmallick/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
      "Successfully built owlready2\n",
      "Installing collected packages: owlready2\n",
      "Successfully installed owlready2-0.47\n"
     ]
    }
   ],
   "source": [
    "!pip install owlready2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2aa796-c8ff-4654-81e1-7914f391f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyMedTermino\n",
      "  Downloading PyMedTermino-0.3.3.tar.gz (34.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: PyMedTermino\n",
      "  Building wheel for PyMedTermino (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMedTermino: filename=PyMedTermino-0.3.3-py3-none-any.whl size=34423018 sha256=93d270f5812df2dc3fe36af78c30fad24f882f8609d72b3ed89ddc4d14c067cf\n",
      "  Stored in directory: /home/kmallick/.cache/pip/wheels/94/ed/fe/df89cd582f8091826e36cecc7cf7fe18c9b92c77d2a872216c\n",
      "Successfully built PyMedTermino\n",
      "Installing collected packages: PyMedTermino\n",
      "Successfully installed PyMedTermino-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMedTermino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254927cf-c8db-4b89-bb0d-6bc58c530245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting umls_downloader\n",
      "  Downloading umls_downloader-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: click in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from umls_downloader) (8.1.7)\n",
      "Collecting more-click (from umls_downloader)\n",
      "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from umls_downloader) (4.12.2)\n",
      "Requirement already satisfied: requests in /home/kmallick/.local/lib/python3.11/site-packages (from umls_downloader) (2.32.3)\n",
      "Collecting pystow (from umls_downloader)\n",
      "  Downloading pystow-0.5.6-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from beautifulsoup4->umls_downloader) (2.5)\n",
      "Requirement already satisfied: tqdm in /home/kmallick/.local/lib/python3.11/site-packages (from pystow->umls_downloader) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2024.2.2)\n",
      "Downloading umls_downloader-0.1.3-py3-none-any.whl (13 kB)\n",
      "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
      "Downloading pystow-0.5.6-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: more-click, pystow, umls_downloader\n",
      "Successfully installed more-click-0.1.2 pystow-0.5.6 umls_downloader-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install umls_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2613a996-594d-41dd-85bc-b52044f1bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), 'predictions.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442ae22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>10370003_label</th>\n",
       "      <th>111975006_label</th>\n",
       "      <th>164889003_label</th>\n",
       "      <th>164890007_label</th>\n",
       "      <th>164909002_label</th>\n",
       "      <th>164917005_label</th>\n",
       "      <th>164934002_label</th>\n",
       "      <th>164947007_label</th>\n",
       "      <th>251146004_label</th>\n",
       "      <th>...</th>\n",
       "      <th>426783006_score</th>\n",
       "      <th>427084000_score</th>\n",
       "      <th>427172004_score</th>\n",
       "      <th>427393009_score</th>\n",
       "      <th>445118002_score</th>\n",
       "      <th>47665007_score</th>\n",
       "      <th>59931005_score</th>\n",
       "      <th>698252002_score</th>\n",
       "      <th>713426002_score</th>\n",
       "      <th>713427006_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03065.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E03604.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR15478.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3309.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2844.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>A3634.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>HR10415.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>HR01691.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>HR00716.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>A0890.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4313 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  10370003_label  111975006_label  164889003_label  \\\n",
       "0      E03065.mat               1                0                1   \n",
       "1      E03604.mat               1                0                1   \n",
       "2     HR15478.mat               1                0                1   \n",
       "3       A3309.mat               1                0                1   \n",
       "4       A2844.mat               1                0                1   \n",
       "...           ...             ...              ...              ...   \n",
       "4308    A3634.mat               1                0                1   \n",
       "4309  HR10415.mat               1                0                1   \n",
       "4310  HR01691.mat               1                0                1   \n",
       "4311  HR00716.mat               1                0                1   \n",
       "4312    A0890.mat               1                0                1   \n",
       "\n",
       "      164890007_label  164909002_label  164917005_label  164934002_label  \\\n",
       "0                   1                0                0                1   \n",
       "1                   1                0                0                1   \n",
       "2                   1                1                0                1   \n",
       "3                   1                0                0                1   \n",
       "4                   1                0                0                1   \n",
       "...               ...              ...              ...              ...   \n",
       "4308                1                0                0                1   \n",
       "4309                1                0                0                1   \n",
       "4310                1                1                0                1   \n",
       "4311                1                0                0                1   \n",
       "4312                1                0                0                1   \n",
       "\n",
       "      164947007_label  251146004_label  ...  426783006_score  427084000_score  \\\n",
       "0                   0                1  ...              1.0              1.0   \n",
       "1                   0                0  ...              1.0              1.0   \n",
       "2                   0                1  ...              1.0              1.0   \n",
       "3                   0                0  ...              1.0              1.0   \n",
       "4                   0                1  ...              1.0              1.0   \n",
       "...               ...              ...  ...              ...              ...   \n",
       "4308                0                1  ...              1.0              1.0   \n",
       "4309                0                1  ...              1.0              1.0   \n",
       "4310                0                1  ...              1.0              1.0   \n",
       "4311                0                1  ...              1.0              1.0   \n",
       "4312                0                1  ...              1.0              1.0   \n",
       "\n",
       "      427172004_score  427393009_score  445118002_score  47665007_score  \\\n",
       "0                 0.0              1.0              0.0             1.0   \n",
       "1                 0.0              1.0              0.0             0.0   \n",
       "2                 0.0              1.0              0.0             1.0   \n",
       "3                 0.0              1.0              0.0             1.0   \n",
       "4                 0.0              1.0              0.0             1.0   \n",
       "...               ...              ...              ...             ...   \n",
       "4308              0.0              1.0              0.0             1.0   \n",
       "4309              0.0              1.0              0.0             1.0   \n",
       "4310              0.0              1.0              0.0             1.0   \n",
       "4311              1.0              1.0              0.0             1.0   \n",
       "4312              0.0              1.0              0.0             1.0   \n",
       "\n",
       "      59931005_score  698252002_score  713426002_score  713427006_score  \n",
       "0           0.000000              1.0              0.0              1.0  \n",
       "1           1.000000              1.0              0.0              1.0  \n",
       "2           0.000000              1.0              0.0              1.0  \n",
       "3           0.000000              0.5              0.0              1.0  \n",
       "4           1.000000              1.0              0.0              1.0  \n",
       "...              ...              ...              ...              ...  \n",
       "4308        1.000000              1.0              0.0              1.0  \n",
       "4309        0.999963              1.0              0.0              1.0  \n",
       "4310        0.000000              1.0              0.0              1.0  \n",
       "4311        0.000000              1.0              0.0              0.0  \n",
       "4312        0.000000              1.0              0.0              0.0  \n",
       "\n",
       "[4313 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e328bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10370003',\n",
       " '111975006',\n",
       " '164889003',\n",
       " '164890007',\n",
       " '164909002',\n",
       " '164917005',\n",
       " '164934002',\n",
       " '164947007',\n",
       " '251146004',\n",
       " '270492004',\n",
       " '284470004',\n",
       " '39732003',\n",
       " '426177001',\n",
       " '426627000',\n",
       " '426783006',\n",
       " '427084000',\n",
       " '427172004',\n",
       " '427393009',\n",
       " '445118002',\n",
       " '47665007',\n",
       " '59931005',\n",
       " '698252002',\n",
       " '713426002',\n",
       " '713427006']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ct_codes = [col.replace('_label', '') for col in df.columns if '_label' in col]\n",
    "\n",
    "ct_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26b2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, code, name, explanation, solution, min_confidence=0.7):\n",
    "        self.code = code\n",
    "        self.name = name\n",
    "        self.explanation = explanation\n",
    "        self.solution = solution\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def is_confident(self, confidence_score):\n",
    "        return confidence_score >= self.min_confidence\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: {self.explanation} - Solution: {self.solution}\"\n",
    "\n",
    "conditions = {\n",
    "    \"111975006\": Condition(\"111975006\", \"Ischemic Heart Disease\",\n",
    "                           \"Reduced blood flow to the heart.\",\n",
    "                           \"Recommend stress test and possible angiography.\"),\n",
    "    \"10370003\": Condition(\"426627000\", \"Arrhythmia\",\n",
    "                           \"Irregular heartbeat.\",\n",
    "                           \"Suggest ECG monitoring and beta-blockers.\"),\n",
    "    \"427172004\": Condition(\"427172004\", \"Conduction Disorder\",\n",
    "                           \"Impaired conduction of heart impulses.\",\n",
    "                           \"Consider pacemaker consultation.\"),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f55f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'snowmed_cts': '111975006|10370003|427172004', 'combined_explanation': 'Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.', 'combined_solution': 'Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.'}\n"
     ]
    }
   ],
   "source": [
    "def decision_graph(predicted_conditions):\n",
    "    explanations = []\n",
    "    solutions = []\n",
    "    co_condition_solutions = []\n",
    "    \n",
    "    for code, confidence_score in predicted_conditions.items():\n",
    "        if code in conditions:\n",
    "            condition = conditions[code]\n",
    "            if condition.is_confident(confidence_score):\n",
    "                explanations.append(condition.explanation)\n",
    "                solutions.append(condition.solution)\n",
    "                \n",
    "                if code == \"426627000\" and predicted_conditions.get(\"427172004\", 0) > 0.8:\n",
    "                    co_condition_solutions.append(\"High risk of heart complications. Immediate intervention recommended.\")\n",
    "    \n",
    "    combined_explanation = \" | \".join(explanations) if explanations else \"No significant condition detected.\"\n",
    "    combined_solution = \" | \".join(solutions + co_condition_solutions) if solutions else \"No action required.\"\n",
    "    \n",
    "    return {\n",
    "        \"snowmed_cts\": '|'.join(predicted_conditions.keys()),\n",
    "        \"combined_explanation\": combined_explanation,\n",
    "        \"combined_solution\": combined_solution\n",
    "    }\n",
    "\n",
    "\n",
    "predicted_conditions_sample = {\n",
    "    \"111975006\": 0.85,\n",
    "    \"10370003\": 0.85,\n",
    "    \"427172004\": 0.9\n",
    "}\n",
    "\n",
    "result = decision_graph(predicted_conditions_sample)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c5d1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_repots(result):\n",
    "    expl = result['combined_explanation']\n",
    "    sol = result['combined_solution']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\n",
    "    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\n",
    "\n",
    "    Highly confident Snowmed CT codes: {result['snowmed_cts']}\n",
    "\n",
    "    Explanation:\n",
    "    {expl}\n",
    "    \n",
    "    Initial Recommendation:\n",
    "    {sol}\n",
    "    \n",
    "    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\n",
    "    \"\"\"\n",
    "\n",
    "    # response = client.chat.completions.create(\n",
    "    #     model=\"gpt-3.5-turbo\",\n",
    "    #     messages = [\n",
    "    #         {\"role\":\"user\", \"content\": prompt}\n",
    "    #     ],\n",
    "    #     max_tokens=300,\n",
    "    #     temperature=0.7\n",
    "    # )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6925fd62-912a-46db-af4a-2e41b4c39026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement 0.43.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for 0.43.2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff80f21-40af-479f-bc0d-d616b5f97431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(result):\n",
    "    expl = result['combined_explanation']\n",
    "    sol = result['combined_solution']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\n",
    "    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\n",
    "\n",
    "    Highly confident Snowmed CT codes: {result['snowmed_cts']}\n",
    "\n",
    "    Explanation:\n",
    "    {expl}\n",
    "    \n",
    "    Initial Recommendation:\n",
    "    {sol}\n",
    "    \n",
    "    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdc1f1e-e3b8-44f7-bae0-dc16f33a2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, model):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids, \n",
    "        max_length=1024, \n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    response_start = generated_text.find(\"###\") + len(\"###\")\n",
    "    response = generated_text[response_start:].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5f87865-29b4-4bc0-8fb6-b897080b2076",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 122] Disk quota exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[1;32m      5\u001b[0m hf_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_czRjYJRuVdTiLsHSDuOTxzrkbZiVHaqGZk\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m login(token\u001b[38;5;241m=\u001b[39mhf_token)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/_login.py:119\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[1;32m    113\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    114\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         )\n\u001b[0;32m--> 119\u001b[0m     _login(token, add_to_git_credential\u001b[38;5;241m=\u001b[39madd_to_git_credential, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[1;32m    121\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/_login.py:408\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[1;32m    406\u001b[0m token_name \u001b[38;5;241m=\u001b[39m token_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessToken\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplayName\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Store token locally\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m _save_token(token\u001b[38;5;241m=\u001b[39mtoken, token_name\u001b[38;5;241m=\u001b[39mtoken_name)\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# Set active token\u001b[39;00m\n\u001b[1;32m    410\u001b[0m _set_active_token(token_name\u001b[38;5;241m=\u001b[39mtoken_name, add_to_git_credential\u001b[38;5;241m=\u001b[39madd_to_git_credential)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_auth.py:203\u001b[0m, in \u001b[0;36m_save_token\u001b[0;34m(token, token_name)\u001b[0m\n\u001b[1;32m    201\u001b[0m stored_tokens \u001b[38;5;241m=\u001b[39m get_stored_tokens()\n\u001b[1;32m    202\u001b[0m stored_tokens[token_name] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 203\u001b[0m _save_stored_tokens(stored_tokens)\n\u001b[1;32m    204\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` has been saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_auth.py:167\u001b[0m, in \u001b[0;36m_save_stored_tokens\u001b[0;34m(stored_tokens)\u001b[0m\n\u001b[1;32m    164\u001b[0m     config\u001b[38;5;241m.\u001b[39mset(token_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, stored_tokens[token_name])\n\u001b[1;32m    166\u001b[0m stored_tokens_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m stored_tokens_path\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m config_file:\n\u001b[1;32m    168\u001b[0m     config\u001b[38;5;241m.\u001b[39mwrite(config_file)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 122] Disk quota exceeded"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = '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'\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620586a-34e0-4767-8b02-6da4be476447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=\"hub\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, config=quantization_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edbe00-4db1-42a2-953a-332bcab479f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3a0809-a5b7-4c7a-a2f3-fb82dcdf3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 26 20:12:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              38W / 250W |   6104MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    244219      C   python                                     6100MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc71b3-206b-4daf-86de-0ef34804e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 226500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72116eec-d01f-4cd3-a1cb-72e0f4903715",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d763c674-dfe6-40e2-8829-32679a00d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a doctor tasked with writing a detailed report for a patient based on their recent ECG analysis. The following conditions have been identified with high confidence:\n",
    "SNOMED CT Codes: 111975006 (Reduced blood flow to the heart), 10370003 (Irregular heartbeat), 427172004 (Impaired conduction of heart impulses).\n",
    "Explanation:\n",
    "Reduced Blood Flow to the Heart: This condition suggests potential coronary artery disease, which may lead to angina or myocardial infarction.\n",
    "Irregular Heartbeat: Indicates arrhythmias such as atrial fibrillation, which can increase the risk of stroke.\n",
    "Impaired Conduction of Heart Impulses: Suggests possible heart block, which may require intervention.\n",
    "Initial Recommendations:\n",
    "Reduced Blood Flow: Recommend a stress test and consider angiography to assess coronary arteries.\n",
    "Irregular Heartbeat: Suggest continuous ECG monitoring and the use of beta-blockers to manage arrhythmias.\n",
    "Impaired Conduction: Consider consulting for a pacemaker if the block is significant.\n",
    "Task:\n",
    "Using your medical expertise, provide an expanded summary that includes:\n",
    "Detailed explanations for each condition.\n",
    "Possible interactions between these conditions.\n",
    "Recommended next steps for treatment and management.\n",
    "Tailor your response to be insightful for a physician assessing this case. Remember, this report is advisory and not a substitute for professional medical advice. This version aims to clarify each section and reduce redundancy, ensuring the AI focuses on delivering a coherent and useful report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a4fe836-c35e-4255-9e12-5a1043ac00e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"u are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\\n    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\\n\\n    Highly confident Snowmed CT codes: 111975006|10370003|427172004\\n\\n    Explanation:\\n    Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.\\n    \\n    Initial Recommendation:\\n    Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.\\n    \\n    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3582cad-b62f-4a42-a226-ba602b273cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(\n",
    "    input_ids=input_ids, \n",
    "    max_length=1024, \n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809a304a-aa6d-43b9-9ed0-26134e5ea671",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3a8440-187c-4851-bafe-fef870d25b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\\n    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\\n\\n    Highly confident Snowmed CT codes: 111975006|10370003|427172004\\n\\n    Explanation:\\n    Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.\\n    \\n    Initial Recommendation:\\n    Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.\\n    \\n    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf6bbc-677f-4af0-b5e2-08037cf41e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bd6eb02d034f68b7fe42d4e73d8522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 00:24:44.957864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d359bdade47bb8fc6227996043f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/59.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058654dc7ad1460d82a051f2a26328c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35da9c64de024390b74a1228bf91f6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00030.safetensors:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c864afcd5ce40f3af6cabaa11c2ca29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3700a3e4ea0d4812aec53ae81f71c603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e922d6d5ac4b209e3b23f0fca1f659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe9ce21988e48d888f077fb98545f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d7802fa79c4f7c8a4e40af5433046f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f107b12084e435ca7321db3ece4d839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d9637a78c4d474eb7d2fafd71a76a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e4588763af4597aa60cd26f4a78efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7006c504ff41a49457ee4e964a94da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0ba0079b2b47c6951ac54e03a6538e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8497aefc5874a8ab6beb314833f110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e97813bafd424498497f53dbf39e0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fbb9f6701f45b5ad751600cb2d74be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5345aec49eb34f10994be4a224b8ea79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05dcf77b5704050afe3ce8b96bd9848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aac66fb1aee4af492244b617a26b402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce14f6c7d4840228a365e6ca291fabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e58e195d319487c9f8c233040e49947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55900de3b2314e60bf83508892993296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9acc348f0d3046aa9ed16fe3ac4eba47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f47938a8154ca28f03519d8eba8cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281eb630e96d46f5a7d582dc969a0874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccc463606434c16ab683c5e20c0a495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07091ef251e4737a5881d8b46d7a203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a37fbca5724580b73f7682c580d1d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0838ce686ffc4784a6f8b749a49db129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00030.safetensors:   0%|          | 0.00/4.66G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bc86869e7d448c989ec1642f40349f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00030.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c808bd2e994dd197d18e37c990f381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00030.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcea3662eca149b6bb0fdf33125e8980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00030.safetensors:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62597e53cb4b459389f5daf4e2aedf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c7ffe98b4e4d3baae61b0ed4a94fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac09fd935734bfa89f768f9451ef9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c99c847f6a488eb4e43cf1becd9cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcc76bf131d45f0bf0f764c07eb89d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\", cache_dir=\"hub\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"hub\")\n",
    "\n",
    "# prompt = \"How many r in strawberry?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "response_token_ids = model.generate(tokenized_message['input_ids'].cuda(),attention_mask=tokenized_message['attention_mask'].cuda(),  max_new_tokens=4096, pad_token_id = tokenizer.eos_token_id)\n",
    "generated_tokens =response_token_ids[:, len(tokenized_message['input_ids'][0]):]\n",
    "generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Anaconda 2024.02)",
   "language": "python",
   "name": "anaconda-2024.02-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
