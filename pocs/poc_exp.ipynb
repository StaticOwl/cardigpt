{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f3528a-8190-4f39-a8be-41f7fe248810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting owlready2\n",
      "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: owlready2\n",
      "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=23936649 sha256=0d81959a091bc145874a64f4efc8bbffdd41c891011a1a833ec53c56c4338e98\n",
      "  Stored in directory: /home/kmallick/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
      "Successfully built owlready2\n",
      "Installing collected packages: owlready2\n",
      "Successfully installed owlready2-0.47\n"
     ]
    }
   ],
   "source": [
    "!pip install owlready2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2aa796-c8ff-4654-81e1-7914f391f495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyMedTermino\n",
      "  Downloading PyMedTermino-0.3.3.tar.gz (34.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.0/34.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: PyMedTermino\n",
      "  Building wheel for PyMedTermino (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyMedTermino: filename=PyMedTermino-0.3.3-py3-none-any.whl size=34423018 sha256=93d270f5812df2dc3fe36af78c30fad24f882f8609d72b3ed89ddc4d14c067cf\n",
      "  Stored in directory: /home/kmallick/.cache/pip/wheels/94/ed/fe/df89cd582f8091826e36cecc7cf7fe18c9b92c77d2a872216c\n",
      "Successfully built PyMedTermino\n",
      "Installing collected packages: PyMedTermino\n",
      "Successfully installed PyMedTermino-0.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install PyMedTermino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "254927cf-c8db-4b89-bb0d-6bc58c530245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting umls_downloader\n",
      "  Downloading umls_downloader-0.1.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: click in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from umls_downloader) (8.1.7)\n",
      "Collecting more-click (from umls_downloader)\n",
      "  Downloading more_click-0.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from umls_downloader) (4.12.2)\n",
      "Requirement already satisfied: requests in /home/kmallick/.local/lib/python3.11/site-packages (from umls_downloader) (2.32.3)\n",
      "Collecting pystow (from umls_downloader)\n",
      "  Downloading pystow-0.5.6-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from beautifulsoup4->umls_downloader) (2.5)\n",
      "Requirement already satisfied: tqdm in /home/kmallick/.local/lib/python3.11/site-packages (from pystow->umls_downloader) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/cent7/anaconda/2024.02/lib/python3.11/site-packages (from requests->umls_downloader) (2024.2.2)\n",
      "Downloading umls_downloader-0.1.3-py3-none-any.whl (13 kB)\n",
      "Downloading more_click-0.1.2-py3-none-any.whl (6.7 kB)\n",
      "Downloading pystow-0.5.6-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: more-click, pystow, umls_downloader\n",
      "Successfully installed more-click-0.1.2 pystow-0.5.6 umls_downloader-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install umls_downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2613a996-594d-41dd-85bc-b52044f1bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), 'predictions.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "442ae22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>10370003_label</th>\n",
       "      <th>111975006_label</th>\n",
       "      <th>164889003_label</th>\n",
       "      <th>164890007_label</th>\n",
       "      <th>164909002_label</th>\n",
       "      <th>164917005_label</th>\n",
       "      <th>164934002_label</th>\n",
       "      <th>164947007_label</th>\n",
       "      <th>251146004_label</th>\n",
       "      <th>...</th>\n",
       "      <th>426783006_score</th>\n",
       "      <th>427084000_score</th>\n",
       "      <th>427172004_score</th>\n",
       "      <th>427393009_score</th>\n",
       "      <th>445118002_score</th>\n",
       "      <th>47665007_score</th>\n",
       "      <th>59931005_score</th>\n",
       "      <th>698252002_score</th>\n",
       "      <th>713426002_score</th>\n",
       "      <th>713427006_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E03065.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E03604.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR15478.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3309.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2844.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4308</th>\n",
       "      <td>A3634.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4309</th>\n",
       "      <td>HR10415.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>HR01691.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>HR00716.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4312</th>\n",
       "      <td>A0890.mat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4313 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  10370003_label  111975006_label  164889003_label  \\\n",
       "0      E03065.mat               1                0                1   \n",
       "1      E03604.mat               1                0                1   \n",
       "2     HR15478.mat               1                0                1   \n",
       "3       A3309.mat               1                0                1   \n",
       "4       A2844.mat               1                0                1   \n",
       "...           ...             ...              ...              ...   \n",
       "4308    A3634.mat               1                0                1   \n",
       "4309  HR10415.mat               1                0                1   \n",
       "4310  HR01691.mat               1                0                1   \n",
       "4311  HR00716.mat               1                0                1   \n",
       "4312    A0890.mat               1                0                1   \n",
       "\n",
       "      164890007_label  164909002_label  164917005_label  164934002_label  \\\n",
       "0                   1                0                0                1   \n",
       "1                   1                0                0                1   \n",
       "2                   1                1                0                1   \n",
       "3                   1                0                0                1   \n",
       "4                   1                0                0                1   \n",
       "...               ...              ...              ...              ...   \n",
       "4308                1                0                0                1   \n",
       "4309                1                0                0                1   \n",
       "4310                1                1                0                1   \n",
       "4311                1                0                0                1   \n",
       "4312                1                0                0                1   \n",
       "\n",
       "      164947007_label  251146004_label  ...  426783006_score  427084000_score  \\\n",
       "0                   0                1  ...              1.0              1.0   \n",
       "1                   0                0  ...              1.0              1.0   \n",
       "2                   0                1  ...              1.0              1.0   \n",
       "3                   0                0  ...              1.0              1.0   \n",
       "4                   0                1  ...              1.0              1.0   \n",
       "...               ...              ...  ...              ...              ...   \n",
       "4308                0                1  ...              1.0              1.0   \n",
       "4309                0                1  ...              1.0              1.0   \n",
       "4310                0                1  ...              1.0              1.0   \n",
       "4311                0                1  ...              1.0              1.0   \n",
       "4312                0                1  ...              1.0              1.0   \n",
       "\n",
       "      427172004_score  427393009_score  445118002_score  47665007_score  \\\n",
       "0                 0.0              1.0              0.0             1.0   \n",
       "1                 0.0              1.0              0.0             0.0   \n",
       "2                 0.0              1.0              0.0             1.0   \n",
       "3                 0.0              1.0              0.0             1.0   \n",
       "4                 0.0              1.0              0.0             1.0   \n",
       "...               ...              ...              ...             ...   \n",
       "4308              0.0              1.0              0.0             1.0   \n",
       "4309              0.0              1.0              0.0             1.0   \n",
       "4310              0.0              1.0              0.0             1.0   \n",
       "4311              1.0              1.0              0.0             1.0   \n",
       "4312              0.0              1.0              0.0             1.0   \n",
       "\n",
       "      59931005_score  698252002_score  713426002_score  713427006_score  \n",
       "0           0.000000              1.0              0.0              1.0  \n",
       "1           1.000000              1.0              0.0              1.0  \n",
       "2           0.000000              1.0              0.0              1.0  \n",
       "3           0.000000              0.5              0.0              1.0  \n",
       "4           1.000000              1.0              0.0              1.0  \n",
       "...              ...              ...              ...              ...  \n",
       "4308        1.000000              1.0              0.0              1.0  \n",
       "4309        0.999963              1.0              0.0              1.0  \n",
       "4310        0.000000              1.0              0.0              1.0  \n",
       "4311        0.000000              1.0              0.0              0.0  \n",
       "4312        0.000000              1.0              0.0              0.0  \n",
       "\n",
       "[4313 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e328bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10370003',\n",
       " '111975006',\n",
       " '164889003',\n",
       " '164890007',\n",
       " '164909002',\n",
       " '164917005',\n",
       " '164934002',\n",
       " '164947007',\n",
       " '251146004',\n",
       " '270492004',\n",
       " '284470004',\n",
       " '39732003',\n",
       " '426177001',\n",
       " '426627000',\n",
       " '426783006',\n",
       " '427084000',\n",
       " '427172004',\n",
       " '427393009',\n",
       " '445118002',\n",
       " '47665007',\n",
       " '59931005',\n",
       " '698252002',\n",
       " '713426002',\n",
       " '713427006']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ct_codes = [col.replace('_label', '') for col in df.columns if '_label' in col]\n",
    "\n",
    "ct_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26b2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Condition:\n",
    "    def __init__(self, code, name, explanation, solution, min_confidence=0.7):\n",
    "        self.code = code\n",
    "        self.name = name\n",
    "        self.explanation = explanation\n",
    "        self.solution = solution\n",
    "        self.min_confidence = min_confidence\n",
    "    \n",
    "    def is_confident(self, confidence_score):\n",
    "        return confidence_score >= self.min_confidence\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: {self.explanation} - Solution: {self.solution}\"\n",
    "\n",
    "conditions = {\n",
    "    \"111975006\": Condition(\"111975006\", \"Ischemic Heart Disease\",\n",
    "                           \"Reduced blood flow to the heart.\",\n",
    "                           \"Recommend stress test and possible angiography.\"),\n",
    "    \"10370003\": Condition(\"426627000\", \"Arrhythmia\",\n",
    "                           \"Irregular heartbeat.\",\n",
    "                           \"Suggest ECG monitoring and beta-blockers.\"),\n",
    "    \"427172004\": Condition(\"427172004\", \"Conduction Disorder\",\n",
    "                           \"Impaired conduction of heart impulses.\",\n",
    "                           \"Consider pacemaker consultation.\"),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f55f003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'snowmed_cts': '111975006|10370003|427172004', 'combined_explanation': 'Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.', 'combined_solution': 'Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.'}\n"
     ]
    }
   ],
   "source": [
    "def decision_graph(predicted_conditions):\n",
    "    explanations = []\n",
    "    solutions = []\n",
    "    co_condition_solutions = []\n",
    "    \n",
    "    for code, confidence_score in predicted_conditions.items():\n",
    "        if code in conditions:\n",
    "            condition = conditions[code]\n",
    "            if condition.is_confident(confidence_score):\n",
    "                explanations.append(condition.explanation)\n",
    "                solutions.append(condition.solution)\n",
    "                \n",
    "                if code == \"426627000\" and predicted_conditions.get(\"427172004\", 0) > 0.8:\n",
    "                    co_condition_solutions.append(\"High risk of heart complications. Immediate intervention recommended.\")\n",
    "    \n",
    "    combined_explanation = \" | \".join(explanations) if explanations else \"No significant condition detected.\"\n",
    "    combined_solution = \" | \".join(solutions + co_condition_solutions) if solutions else \"No action required.\"\n",
    "    \n",
    "    return {\n",
    "        \"snowmed_cts\": '|'.join(predicted_conditions.keys()),\n",
    "        \"combined_explanation\": combined_explanation,\n",
    "        \"combined_solution\": combined_solution\n",
    "    }\n",
    "\n",
    "\n",
    "predicted_conditions_sample = {\n",
    "    \"111975006\": 0.85,\n",
    "    \"10370003\": 0.85,\n",
    "    \"427172004\": 0.9\n",
    "}\n",
    "\n",
    "result = decision_graph(predicted_conditions_sample)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c5d1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "def generate_repots(result):\n",
    "    expl = result['combined_explanation']\n",
    "    sol = result['combined_solution']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\n",
    "    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\n",
    "\n",
    "    Highly confident Snowmed CT codes: {result['snowmed_cts']}\n",
    "\n",
    "    Explanation:\n",
    "    {expl}\n",
    "    \n",
    "    Initial Recommendation:\n",
    "    {sol}\n",
    "    \n",
    "    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\n",
    "    \"\"\"\n",
    "\n",
    "    # response = client.chat.completions.create(\n",
    "    #     model=\"gpt-3.5-turbo\",\n",
    "    #     messages = [\n",
    "    #         {\"role\":\"user\", \"content\": prompt}\n",
    "    #     ],\n",
    "    #     max_tokens=300,\n",
    "    #     temperature=0.7\n",
    "    # )\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6925fd62-912a-46db-af4a-2e41b4c39026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement 0.43.2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for 0.43.2\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aff80f21-40af-479f-bc0d-d616b5f97431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(result):\n",
    "    expl = result['combined_explanation']\n",
    "    sol = result['combined_solution']\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\n",
    "    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\n",
    "\n",
    "    Highly confident Snowmed CT codes: {result['snowmed_cts']}\n",
    "\n",
    "    Explanation:\n",
    "    {expl}\n",
    "    \n",
    "    Initial Recommendation:\n",
    "    {sol}\n",
    "    \n",
    "    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdc1f1e-e3b8-44f7-bae0-dc16f33a2367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, model):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids, \n",
    "        max_length=1024, \n",
    "        temperature=0.7,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    response_start = generated_text.find(\"###\") + len(\"###\")\n",
    "    response = generated_text[response_start:].strip()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f87865-29b4-4bc0-8fb6-b897080b2076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc5af5ca4e649ae830942d40f723928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "hf_token = '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'\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620586a-34e0-4767-8b02-6da4be476447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=\"hub\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, config=quantization_config, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edbe00-4db1-42a2-953a-332bcab479f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f3a0809-a5b7-4c7a-a2f3-fb82dcdf3087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Oct 26 20:12:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              38W / 250W |   6104MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A    244219      C   python                                     6100MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fc71b3-206b-4daf-86de-0ef34804e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 226500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72116eec-d01f-4cd3-a1cb-72e0f4903715",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = create_prompt(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d763c674-dfe6-40e2-8829-32679a00d59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a doctor tasked with writing a detailed report for a patient based on their recent ECG analysis. The following conditions have been identified with high confidence:\n",
    "SNOMED CT Codes: 111975006 (Reduced blood flow to the heart), 10370003 (Irregular heartbeat), 427172004 (Impaired conduction of heart impulses).\n",
    "Explanation:\n",
    "Reduced Blood Flow to the Heart: This condition suggests potential coronary artery disease, which may lead to angina or myocardial infarction.\n",
    "Irregular Heartbeat: Indicates arrhythmias such as atrial fibrillation, which can increase the risk of stroke.\n",
    "Impaired Conduction of Heart Impulses: Suggests possible heart block, which may require intervention.\n",
    "Initial Recommendations:\n",
    "Reduced Blood Flow: Recommend a stress test and consider angiography to assess coronary arteries.\n",
    "Irregular Heartbeat: Suggest continuous ECG monitoring and the use of beta-blockers to manage arrhythmias.\n",
    "Impaired Conduction: Consider consulting for a pacemaker if the block is significant.\n",
    "Task:\n",
    "Using your medical expertise, provide an expanded summary that includes:\n",
    "Detailed explanations for each condition.\n",
    "Possible interactions between these conditions.\n",
    "Recommended next steps for treatment and management.\n",
    "Tailor your response to be insightful for a physician assessing this case. Remember, this report is advisory and not a substitute for professional medical advice. This version aims to clarify each section and reduce redundancy, ensuring the AI focuses on delivering a coherent and useful report\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a4fe836-c35e-4255-9e12-5a1043ac00e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"u are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\\n    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\\n\\n    Highly confident Snowmed CT codes: 111975006|10370003|427172004\\n\\n    Explanation:\\n    Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.\\n    \\n    Initial Recommendation:\\n    Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.\\n    \\n    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(prompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3582cad-b62f-4a42-a226-ba602b273cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "output = model.generate(\n",
    "    input_ids=input_ids, \n",
    "    max_length=1024, \n",
    "    temperature=0.7,\n",
    "    num_return_sequences=1,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809a304a-aa6d-43b9-9ed0-26134e5ea671",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb3a8440-187c-4851-bafe-fef870d25b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a doctor. You are going to write a report for a patient. I have developed a solution which is giving you some explanation and some solutions.\\n    Based on a patient's recent ECG analysis, the following conditions have been confidently identified:\\n\\n    Highly confident Snowmed CT codes: 111975006|10370003|427172004\\n\\n    Explanation:\\n    Reduced blood flow to the heart. | Irregular heartbeat. | Impaired conduction of heart impulses.\\n    \\n    Initial Recommendation:\\n    Recommend stress test and possible angiography. | Suggest ECG monitoring and beta-blockers. | Consider pacemaker consultation.\\n    \\n    Using your medical knowledge, provide an expanded summary, including detailed explanations for each identified condition, possible interactions between them, and recommended next steps. Tailor your response to be insightful for a physician assessing a case with these findings.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf6bbc-677f-4af0-b5e2-08037cf41e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 01:46:08.983364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730007969.011755   21221 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730007969.020661   21221 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-27 01:46:09.072833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af34e45fecc84ccb98ca01a6ba80f401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\", cache_dir=\"hub\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=\"hub\")\n",
    "\n",
    "# prompt = \"How many r in strawberry?\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "tokenized_message = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\", return_dict=True)\n",
    "response_token_ids = model.generate(tokenized_message['input_ids'].cuda(),attention_mask=tokenized_message['attention_mask'].cuda(),  max_new_tokens=4096, pad_token_id = tokenizer.eos_token_id)\n",
    "generated_tokens =response_token_ids[:, len(tokenized_message['input_ids'][0]):]\n",
    "generated_text = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
