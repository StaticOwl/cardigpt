digraph {
	graph [size="249.45,249.45"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	47700274645520 [label="
 (1, 24)" fillcolor=darkolivegreen1]
	47700274436400 [label=AddmmBackward0]
	47700274436304 -> 47700274436400
	47701425875056 [label="fc.bias
 (24)" fillcolor=lightblue]
	47701425875056 -> 47700274436304
	47700274436304 [label=AccumulateGrad]
	47701425526032 -> 47700274436400
	47701425526032 [label=CatBackward0]
	47701425526272 -> 47701425526032
	47701425526272 [label=AddmmBackward0]
	47701425526368 -> 47701425526272
	47701425874864 [label="small_fc.bias
 (10)" fillcolor=lightblue]
	47701425874864 -> 47701425526368
	47701425526368 [label=AccumulateGrad]
	47701425526320 -> 47701425526272
	47701425526320 [label=TBackward0]
	47701425526416 -> 47701425526320
	47701425874768 [label="small_fc.weight
 (10, 5)" fillcolor=lightblue]
	47701425874768 -> 47701425526416
	47701425526416 [label=AccumulateGrad]
	47701425525984 -> 47701425526032
	47701425525984 [label=ViewBackward0]
	47701425526608 -> 47701425525984
	47701425526608 [label=SqueezeBackward1]
	47701425526512 -> 47701425526608
	47701425526512 [label=MeanBackward1]
	47701425526704 -> 47701425526512
	47701425526704 [label=UnsqueezeBackward0]
	47701425526800 -> 47701425526704
	47701425526800 [label=AddBackward0]
	47701425526896 -> 47701425526800
	47701425526896 [label=MulBackward0]
	47701425527040 -> 47701425526896
	47701425527040 [label=AddBackward0]
	47701425527184 -> 47701425527040
	47701425527184 [label=MulBackward0]
	47701425527328 -> 47701425527184
	47701425527328 [label=SigmoidBackward0]
	47701425527472 -> 47701425527328
	47701425527472 [label=ConvolutionBackward0]
	47701425527568 -> 47701425527472
	47701425527568 [label=SqueezeBackward1]
	47701425527760 -> 47701425527568
	47701425527760 [label=MeanBackward1]
	47701425527856 -> 47701425527760
	47701425527856 [label=UnsqueezeBackward0]
	47701425527952 -> 47701425527856
	47701425527952 [label=CatBackward0]
	47701425527280 -> 47701425527952
	47701425527280 [label=ReluBackward0]
	47701425528144 -> 47701425527280
	47701425528144 [label=CudnnBatchNormBackward0]
	47701425528240 -> 47701425528144
	47701425528240 [label=ConvolutionBackward0]
	47701425526848 -> 47701425528240
	47701425526848 [label=AddBackward0]
	47701425528528 -> 47701425526848
	47701425528528 [label=MulBackward0]
	47701425528672 -> 47701425528528
	47701425528672 [label=AddBackward0]
	47701425528816 -> 47701425528672
	47701425528816 [label=MulBackward0]
	47701425528960 -> 47701425528816
	47701425528960 [label=SigmoidBackward0]
	47701425529104 -> 47701425528960
	47701425529104 [label=ConvolutionBackward0]
	47701425529200 -> 47701425529104
	47701425529200 [label=SqueezeBackward1]
	47701425529392 -> 47701425529200
	47701425529392 [label=MeanBackward1]
	47701425529488 -> 47701425529392
	47701425529488 [label=UnsqueezeBackward0]
	47701425529584 -> 47701425529488
	47701425529584 [label=CatBackward0]
	47701425528912 -> 47701425529584
	47701425528912 [label=ReluBackward0]
	47701425529776 -> 47701425528912
	47701425529776 [label=CudnnBatchNormBackward0]
	47701425529872 -> 47701425529776
	47701425529872 [label=ConvolutionBackward0]
	47701425528480 -> 47701425529872
	47701425528480 [label=AddBackward0]
	47701425530160 -> 47701425528480
	47701425530160 [label=MulBackward0]
	47701425530304 -> 47701425530160
	47701425530304 [label=AddBackward0]
	47701425530448 -> 47701425530304
	47701425530448 [label=MulBackward0]
	47701425530592 -> 47701425530448
	47701425530592 [label=SigmoidBackward0]
	47701425530736 -> 47701425530592
	47701425530736 [label=ConvolutionBackward0]
	47701425530832 -> 47701425530736
	47701425530832 [label=SqueezeBackward1]
	47701425531024 -> 47701425530832
	47701425531024 [label=MeanBackward1]
	47701425531120 -> 47701425531024
	47701425531120 [label=UnsqueezeBackward0]
	47701425531216 -> 47701425531120
	47701425531216 [label=CatBackward0]
	47701425530544 -> 47701425531216
	47701425530544 [label=ReluBackward0]
	47701425531408 -> 47701425530544
	47701425531408 [label=CudnnBatchNormBackward0]
	47701425531504 -> 47701425531408
	47701425531504 [label=ConvolutionBackward0]
	47701425531696 -> 47701425531504
	47701425531696 [label=AddBackward0]
	47701425531840 -> 47701425531696
	47701425531840 [label=MulBackward0]
	47701425531984 -> 47701425531840
	47701425531984 [label=AddBackward0]
	47701425532128 -> 47701425531984
	47701425532128 [label=MulBackward0]
	47701425532272 -> 47701425532128
	47701425532272 [label=SigmoidBackward0]
	47701425532416 -> 47701425532272
	47701425532416 [label=ConvolutionBackward0]
	47701425532512 -> 47701425532416
	47701425532512 [label=SqueezeBackward1]
	47701425532704 -> 47701425532512
	47701425532704 [label=MeanBackward1]
	47701425532800 -> 47701425532704
	47701425532800 [label=UnsqueezeBackward0]
	47701425532896 -> 47701425532800
	47701425532896 [label=CatBackward0]
	47701425532224 -> 47701425532896
	47701425532224 [label=ReluBackward0]
	47701425533088 -> 47701425532224
	47701425533088 [label=CudnnBatchNormBackward0]
	47701425533184 -> 47701425533088
	47701425533184 [label=ConvolutionBackward0]
	47701425531792 -> 47701425533184
	47701425531792 [label=AddBackward0]
	47701425533472 -> 47701425531792
	47701425533472 [label=MulBackward0]
	47701425533616 -> 47701425533472
	47701425533616 [label=AddBackward0]
	47701425533760 -> 47701425533616
	47701425533760 [label=MulBackward0]
	47701425533904 -> 47701425533760
	47701425533904 [label=SigmoidBackward0]
	47701425534048 -> 47701425533904
	47701425534048 [label=ConvolutionBackward0]
	47701425534144 -> 47701425534048
	47701425534144 [label=SqueezeBackward1]
	47701425534336 -> 47701425534144
	47701425534336 [label=MeanBackward1]
	47701425534432 -> 47701425534336
	47701425534432 [label=UnsqueezeBackward0]
	47701425534528 -> 47701425534432
	47701425534528 [label=CatBackward0]
	47701425533856 -> 47701425534528
	47701425533856 [label=ReluBackward0]
	47701425534720 -> 47701425533856
	47701425534720 [label=CudnnBatchNormBackward0]
	47701425534816 -> 47701425534720
	47701425534816 [label=ConvolutionBackward0]
	47701425533424 -> 47701425534816
	47701425533424 [label=AddBackward0]
	47701425535104 -> 47701425533424
	47701425535104 [label=MulBackward0]
	47701425535248 -> 47701425535104
	47701425535248 [label=AddBackward0]
	47701425535392 -> 47701425535248
	47701425535392 [label=MulBackward0]
	47701425535536 -> 47701425535392
	47701425535536 [label=SigmoidBackward0]
	47701425535680 -> 47701425535536
	47701425535680 [label=ConvolutionBackward0]
	47701425535776 -> 47701425535680
	47701425535776 [label=SqueezeBackward1]
	47701425535968 -> 47701425535776
	47701425535968 [label=MeanBackward1]
	47701425536064 -> 47701425535968
	47701425536064 [label=UnsqueezeBackward0]
	47701425536160 -> 47701425536064
	47701425536160 [label=CatBackward0]
	47701425535488 -> 47701425536160
	47701425535488 [label=ReluBackward0]
	47701425536352 -> 47701425535488
	47701425536352 [label=CudnnBatchNormBackward0]
	47701425536448 -> 47701425536352
	47701425536448 [label=ConvolutionBackward0]
	47701425535056 -> 47701425536448
	47701425535056 [label=AddBackward0]
	47701425536736 -> 47701425535056
	47701425536736 [label=MulBackward0]
	47701425536880 -> 47701425536736
	47701425536880 [label=AddBackward0]
	47701425536976 -> 47701425536880
	47701425536976 [label=MulBackward0]
	47700274725072 -> 47701425536976
	47700274725072 [label=SigmoidBackward0]
	47700274725216 -> 47700274725072
	47700274725216 [label=ConvolutionBackward0]
	47700274725312 -> 47700274725216
	47700274725312 [label=SqueezeBackward1]
	47700274725504 -> 47700274725312
	47700274725504 [label=MeanBackward1]
	47700274725600 -> 47700274725504
	47700274725600 [label=UnsqueezeBackward0]
	47700274725696 -> 47700274725600
	47700274725696 [label=CatBackward0]
	47700274725024 -> 47700274725696
	47700274725024 [label=ReluBackward0]
	47700274725888 -> 47700274725024
	47700274725888 [label=CudnnBatchNormBackward0]
	47700274725984 -> 47700274725888
	47700274725984 [label=ConvolutionBackward0]
	47701425536688 -> 47700274725984
	47701425536688 [label=AddBackward0]
	47700274726272 -> 47701425536688
	47700274726272 [label=MulBackward0]
	47700274726416 -> 47700274726272
	47700274726416 [label=AddBackward0]
	47700274726560 -> 47700274726416
	47700274726560 [label=MulBackward0]
	47700274726704 -> 47700274726560
	47700274726704 [label=SigmoidBackward0]
	47700274726848 -> 47700274726704
	47700274726848 [label=ConvolutionBackward0]
	47700274726944 -> 47700274726848
	47700274726944 [label=SqueezeBackward1]
	47700274727136 -> 47700274726944
	47700274727136 [label=MeanBackward1]
	47700274727232 -> 47700274727136
	47700274727232 [label=UnsqueezeBackward0]
	47700274727328 -> 47700274727232
	47700274727328 [label=CatBackward0]
	47700274726656 -> 47700274727328
	47700274726656 [label=ReluBackward0]
	47700274727520 -> 47700274726656
	47700274727520 [label=CudnnBatchNormBackward0]
	47700274727616 -> 47700274727520
	47700274727616 [label=ConvolutionBackward0]
	47700274726224 -> 47700274727616
	47700274726224 [label=AddBackward0]
	47700274727904 -> 47700274726224
	47700274727904 [label=MulBackward0]
	47700274728048 -> 47700274727904
	47700274728048 [label=AddBackward0]
	47700274728192 -> 47700274728048
	47700274728192 [label=MulBackward0]
	47700274728336 -> 47700274728192
	47700274728336 [label=SigmoidBackward0]
	47700274728480 -> 47700274728336
	47700274728480 [label=ConvolutionBackward0]
	47700274728576 -> 47700274728480
	47700274728576 [label=SqueezeBackward1]
	47700274728768 -> 47700274728576
	47700274728768 [label=MeanBackward1]
	47700274728864 -> 47700274728768
	47700274728864 [label=UnsqueezeBackward0]
	47700274728960 -> 47700274728864
	47700274728960 [label=CatBackward0]
	47700274728288 -> 47700274728960
	47700274728288 [label=ReluBackward0]
	47700274729152 -> 47700274728288
	47700274729152 [label=CudnnBatchNormBackward0]
	47700274729248 -> 47700274729152
	47700274729248 [label=ConvolutionBackward0]
	47700274729440 -> 47700274729248
	47700274729440 [label=AddBackward0]
	47700274729584 -> 47700274729440
	47700274729584 [label=MulBackward0]
	47700274729728 -> 47700274729584
	47700274729728 [label=AddBackward0]
	47700274729872 -> 47700274729728
	47700274729872 [label=MulBackward0]
	47700274730016 -> 47700274729872
	47700274730016 [label=SigmoidBackward0]
	47700274730160 -> 47700274730016
	47700274730160 [label=ConvolutionBackward0]
	47700274730256 -> 47700274730160
	47700274730256 [label=SqueezeBackward1]
	47700274730448 -> 47700274730256
	47700274730448 [label=MeanBackward1]
	47700274730544 -> 47700274730448
	47700274730544 [label=UnsqueezeBackward0]
	47700274730640 -> 47700274730544
	47700274730640 [label=CatBackward0]
	47700274729968 -> 47700274730640
	47700274729968 [label=ReluBackward0]
	47700274730832 -> 47700274729968
	47700274730832 [label=CudnnBatchNormBackward0]
	47700274730928 -> 47700274730832
	47700274730928 [label=ConvolutionBackward0]
	47700274729536 -> 47700274730928
	47700274729536 [label=AddBackward0]
	47700274731216 -> 47700274729536
	47700274731216 [label=MulBackward0]
	47700274731360 -> 47700274731216
	47700274731360 [label=AddBackward0]
	47700274731504 -> 47700274731360
	47700274731504 [label=MulBackward0]
	47700274731648 -> 47700274731504
	47700274731648 [label=SigmoidBackward0]
	47700274731792 -> 47700274731648
	47700274731792 [label=ConvolutionBackward0]
	47700274731888 -> 47700274731792
	47700274731888 [label=SqueezeBackward1]
	47700274732080 -> 47700274731888
	47700274732080 [label=MeanBackward1]
	47700274732176 -> 47700274732080
	47700274732176 [label=UnsqueezeBackward0]
	47700274732272 -> 47700274732176
	47700274732272 [label=CatBackward0]
	47700274731600 -> 47700274732272
	47700274731600 [label=ReluBackward0]
	47700274732464 -> 47700274731600
	47700274732464 [label=CudnnBatchNormBackward0]
	47700274732560 -> 47700274732464
	47700274732560 [label=ConvolutionBackward0]
	47700274731168 -> 47700274732560
	47700274731168 [label=AddBackward0]
	47700274732848 -> 47700274731168
	47700274732848 [label=MulBackward0]
	47700274732992 -> 47700274732848
	47700274732992 [label=AddBackward0]
	47700274733136 -> 47700274732992
	47700274733136 [label=MulBackward0]
	47700274733280 -> 47700274733136
	47700274733280 [label=SigmoidBackward0]
	47700274733424 -> 47700274733280
	47700274733424 [label=ConvolutionBackward0]
	47700274733520 -> 47700274733424
	47700274733520 [label=SqueezeBackward1]
	47700274733712 -> 47700274733520
	47700274733712 [label=MeanBackward1]
	47700274733808 -> 47700274733712
	47700274733808 [label=UnsqueezeBackward0]
	47700274733904 -> 47700274733808
	47700274733904 [label=CatBackward0]
	47700274733232 -> 47700274733904
	47700274733232 [label=ReluBackward0]
	47700274734096 -> 47700274733232
	47700274734096 [label=CudnnBatchNormBackward0]
	47700274734192 -> 47700274734096
	47700274734192 [label=ConvolutionBackward0]
	47700274732800 -> 47700274734192
	47700274732800 [label=AddBackward0]
	47700274734480 -> 47700274732800
	47700274734480 [label=MulBackward0]
	47700274734624 -> 47700274734480
	47700274734624 [label=AddBackward0]
	47700274734768 -> 47700274734624
	47700274734768 [label=MulBackward0]
	47700274734912 -> 47700274734768
	47700274734912 [label=SigmoidBackward0]
	47700274735056 -> 47700274734912
	47700274735056 [label=ConvolutionBackward0]
	47700274735152 -> 47700274735056
	47700274735152 [label=SqueezeBackward1]
	47700274735344 -> 47700274735152
	47700274735344 [label=MeanBackward1]
	47700274735440 -> 47700274735344
	47700274735440 [label=UnsqueezeBackward0]
	47700274735536 -> 47700274735440
	47700274735536 [label=CatBackward0]
	47700274734864 -> 47700274735536
	47700274734864 [label=ReluBackward0]
	47700274735728 -> 47700274734864
	47700274735728 [label=CudnnBatchNormBackward0]
	47700274735824 -> 47700274735728
	47700274735824 [label=ConvolutionBackward0]
	47700274736016 -> 47700274735824
	47700274736016 [label=AddBackward0]
	47700274736160 -> 47700274736016
	47700274736160 [label=MulBackward0]
	47700274736304 -> 47700274736160
	47700274736304 [label=AddBackward0]
	47700274736448 -> 47700274736304
	47700274736448 [label=MulBackward0]
	47700274736592 -> 47700274736448
	47700274736592 [label=SigmoidBackward0]
	47700274736736 -> 47700274736592
	47700274736736 [label=ConvolutionBackward0]
	47700274736832 -> 47700274736736
	47700274736832 [label=SqueezeBackward1]
	47700274737024 -> 47700274736832
	47700274737024 [label=MeanBackward1]
	47700274737120 -> 47700274737024
	47700274737120 [label=UnsqueezeBackward0]
	47700274737216 -> 47700274737120
	47700274737216 [label=CatBackward0]
	47700274736544 -> 47700274737216
	47700274736544 [label=ReluBackward0]
	47700274737408 -> 47700274736544
	47700274737408 [label=CudnnBatchNormBackward0]
	47700274737504 -> 47700274737408
	47700274737504 [label=ConvolutionBackward0]
	47700274736112 -> 47700274737504
	47700274736112 [label=AddBackward0]
	47700274737792 -> 47700274736112
	47700274737792 [label=MulBackward0]
	47700274737936 -> 47700274737792
	47700274737936 [label=AddBackward0]
	47700274738080 -> 47700274737936
	47700274738080 [label=MulBackward0]
	47700274738224 -> 47700274738080
	47700274738224 [label=SigmoidBackward0]
	47700274738368 -> 47700274738224
	47700274738368 [label=ConvolutionBackward0]
	47700274738464 -> 47700274738368
	47700274738464 [label=SqueezeBackward1]
	47700274738656 -> 47700274738464
	47700274738656 [label=MeanBackward1]
	47700274738752 -> 47700274738656
	47700274738752 [label=UnsqueezeBackward0]
	47700274738848 -> 47700274738752
	47700274738848 [label=CatBackward0]
	47700274738176 -> 47700274738848
	47700274738176 [label=ReluBackward0]
	47700274739040 -> 47700274738176
	47700274739040 [label=CudnnBatchNormBackward0]
	47700274739136 -> 47700274739040
	47700274739136 [label=ConvolutionBackward0]
	47700274737744 -> 47700274739136
	47700274737744 [label=AddBackward0]
	47700274739424 -> 47700274737744
	47700274739424 [label=MulBackward0]
	47700274739568 -> 47700274739424
	47700274739568 [label=AddBackward0]
	47700274739712 -> 47700274739568
	47700274739712 [label=MulBackward0]
	47700274739856 -> 47700274739712
	47700274739856 [label=SigmoidBackward0]
	47700274740000 -> 47700274739856
	47700274740000 [label=ConvolutionBackward0]
	47700274740096 -> 47700274740000
	47700274740096 [label=SqueezeBackward1]
	47700274740288 -> 47700274740096
	47700274740288 [label=MeanBackward1]
	47700274740384 -> 47700274740288
	47700274740384 [label=UnsqueezeBackward0]
	47700274740480 -> 47700274740384
	47700274740480 [label=CatBackward0]
	47700274739808 -> 47700274740480
	47700274739808 [label=ReluBackward0]
	47700274740672 -> 47700274739808
	47700274740672 [label=CudnnBatchNormBackward0]
	47700274740768 -> 47700274740672
	47700274740768 [label=ConvolutionBackward0]
	47700274739376 -> 47700274740768
	47700274739376 [label=SqueezeBackward1]
	47700274741056 -> 47700274739376
	47700274741056 [label=MaxPool2DWithIndicesBackward0]
	47700274741152 -> 47700274741056
	47700274741152 [label=UnsqueezeBackward0]
	47700274741200 -> 47700274741152
	47700274741200 [label=ReluBackward0]
	47700274675872 -> 47700274741200
	47700274675872 [label=CudnnBatchNormBackward0]
	47700274675968 -> 47700274675872
	47700274675968 [label=ConvolutionBackward0]
	47700274676160 -> 47700274675968
	47701425314448 [label="conv1.weight
 (64, 12, 15)" fillcolor=lightblue]
	47701425314448 -> 47700274676160
	47700274676160 [label=AccumulateGrad]
	47700274676112 -> 47700274675968
	47701425315504 [label="conv1.bias
 (64)" fillcolor=lightblue]
	47701425315504 -> 47700274676112
	47700274676112 [label=AccumulateGrad]
	47700274675920 -> 47700274675872
	47701425315600 [label="bn1.weight
 (64)" fillcolor=lightblue]
	47701425315600 -> 47700274675920
	47700274675920 [label=AccumulateGrad]
	47700274675776 -> 47700274675872
	47701425315696 [label="bn1.bias
 (64)" fillcolor=lightblue]
	47701425315696 -> 47700274675776
	47700274675776 [label=AccumulateGrad]
	47700274740960 -> 47700274740768
	47701425316080 [label="layers.0.0.conv1.weight
 (64, 64, 7)" fillcolor=lightblue]
	47701425316080 -> 47700274740960
	47700274740960 [label=AccumulateGrad]
	47700274740720 -> 47700274740672
	47701425316176 [label="layers.0.0.bn.weight
 (64)" fillcolor=lightblue]
	47701425316176 -> 47700274740720
	47700274740720 [label=AccumulateGrad]
	47700274740192 -> 47700274740672
	47701425316272 [label="layers.0.0.bn.bias
 (64)" fillcolor=lightblue]
	47701425316272 -> 47700274740192
	47700274740192 [label=AccumulateGrad]
	47700274740576 -> 47700274740480
	47700274740576 [label=ReluBackward0]
	47700274740912 -> 47700274740576
	47700274740912 [label=CudnnBatchNormBackward0]
	47700274741104 -> 47700274740912
	47700274741104 [label=ConvolutionBackward0]
	47700274739376 -> 47700274741104
	47700274740960 -> 47700274741104
	47700274740720 -> 47700274740912
	47700274740192 -> 47700274740912
	47700274740048 -> 47700274740000
	47701425316944 [label="layers.0.0.fc.1.weight
 (64, 128, 1)" fillcolor=lightblue]
	47701425316944 -> 47700274740048
	47700274740048 [label=AccumulateGrad]
	47700274739904 -> 47700274740000
	47701425317040 [label="layers.0.0.fc.1.bias
 (64)" fillcolor=lightblue]
	47701425317040 -> 47700274739904
	47700274739904 [label=AccumulateGrad]
	47700274739808 -> 47700274739712
	47700274739664 -> 47700274739568
	47700274739664 [label=MulBackward0]
	47700274740144 -> 47700274739664
	47700274740144 [label=RsubBackward1]
	47700274739856 -> 47700274740144
	47700274740576 -> 47700274739664
	47700274739520 -> 47700274739424
	47700274739520 [label=ExpandBackward0]
	47700274740336 -> 47700274739520
	47700274740336 [label=ViewBackward0]
	47700274739760 -> 47700274740336
	47700274739760 [label=SigmoidBackward0]
	47700274740528 -> 47700274739760
	47700274740528 [label=MmBackward0]
	47700274740864 -> 47700274740528
	47700274740864 [label=ReluBackward0]
	47700274740624 -> 47700274740864
	47700274740624 [label=MmBackward0]
	47700274676064 -> 47700274740624
	47700274676064 [label=ViewBackward0]
	47700274676304 -> 47700274676064
	47700274676304 [label=SqueezeBackward1]
	47700274676400 -> 47700274676304
	47700274676400 [label=MeanBackward1]
	47700274676496 -> 47700274676400
	47700274676496 [label=UnsqueezeBackward0]
	47700274739568 -> 47700274676496
	47700274676016 -> 47700274740624
	47700274676016 [label=TBackward0]
	47700274676448 -> 47700274676016
	47701425316752 [label="layers.0.0.se.fc.0.weight
 (4, 64)" fillcolor=lightblue]
	47701425316752 -> 47700274676448
	47700274676448 [label=AccumulateGrad]
	47700274740816 -> 47700274740528
	47700274740816 [label=TBackward0]
	47700274741008 -> 47700274740816
	47701425316848 [label="layers.0.0.se.fc.2.weight
 (64, 4)" fillcolor=lightblue]
	47701425316848 -> 47700274741008
	47700274741008 [label=AccumulateGrad]
	47700274739376 -> 47700274737744
	47700274739328 -> 47700274739136
	47701425317136 [label="layers.0.1.conv1.weight
 (64, 64, 7)" fillcolor=lightblue]
	47701425317136 -> 47700274739328
	47700274739328 [label=AccumulateGrad]
	47700274739088 -> 47700274739040
	47701425317232 [label="layers.0.1.bn.weight
 (64)" fillcolor=lightblue]
	47701425317232 -> 47700274739088
	47700274739088 [label=AccumulateGrad]
	47700274738560 -> 47700274739040
	47701425317328 [label="layers.0.1.bn.bias
 (64)" fillcolor=lightblue]
	47701425317328 -> 47700274738560
	47700274738560 [label=AccumulateGrad]
	47700274738944 -> 47700274738848
	47700274738944 [label=ReluBackward0]
	47700274739280 -> 47700274738944
	47700274739280 [label=CudnnBatchNormBackward0]
	47700274739472 -> 47700274739280
	47700274739472 [label=ConvolutionBackward0]
	47700274737744 -> 47700274739472
	47700274739328 -> 47700274739472
	47700274739088 -> 47700274739280
	47700274738560 -> 47700274739280
	47700274738416 -> 47700274738368
	47701425318000 [label="layers.0.1.fc.1.weight
 (64, 128, 1)" fillcolor=lightblue]
	47701425318000 -> 47700274738416
	47700274738416 [label=AccumulateGrad]
	47700274738272 -> 47700274738368
	47701425318096 [label="layers.0.1.fc.1.bias
 (64)" fillcolor=lightblue]
	47701425318096 -> 47700274738272
	47700274738272 [label=AccumulateGrad]
	47700274738176 -> 47700274738080
	47700274738032 -> 47700274737936
	47700274738032 [label=MulBackward0]
	47700274738512 -> 47700274738032
	47700274738512 [label=RsubBackward1]
	47700274738224 -> 47700274738512
	47700274738944 -> 47700274738032
	47700274737888 -> 47700274737792
	47700274737888 [label=ExpandBackward0]
	47700274738704 -> 47700274737888
	47700274738704 [label=ViewBackward0]
	47700274738128 -> 47700274738704
	47700274738128 [label=SigmoidBackward0]
	47700274738896 -> 47700274738128
	47700274738896 [label=MmBackward0]
	47700274739952 -> 47700274738896
	47700274739952 [label=ReluBackward0]
	47700274738992 -> 47700274739952
	47700274738992 [label=MmBackward0]
	47700274739616 -> 47700274738992
	47700274739616 [label=ViewBackward0]
	47700274676544 -> 47700274739616
	47700274676544 [label=SqueezeBackward1]
	47700274676256 -> 47700274676544
	47700274676256 [label=MeanBackward1]
	47700274676640 -> 47700274676256
	47700274676640 [label=UnsqueezeBackward0]
	47700274737936 -> 47700274676640
	47700274740432 -> 47700274738992
	47700274740432 [label=TBackward0]
	47700274676208 -> 47700274740432
	47701425317808 [label="layers.0.1.se.fc.0.weight
 (4, 64)" fillcolor=lightblue]
	47701425317808 -> 47700274676208
	47700274676208 [label=AccumulateGrad]
	47700274739184 -> 47700274738896
	47700274739184 [label=TBackward0]
	47700274740240 -> 47700274739184
	47701425317904 [label="layers.0.1.se.fc.2.weight
 (64, 4)" fillcolor=lightblue]
	47701425317904 -> 47700274740240
	47700274740240 [label=AccumulateGrad]
	47700274737744 -> 47700274736112
	47700274737696 -> 47700274737504
	47701425318192 [label="layers.0.2.conv1.weight
 (64, 64, 7)" fillcolor=lightblue]
	47701425318192 -> 47700274737696
	47700274737696 [label=AccumulateGrad]
	47700274737456 -> 47700274737408
	47701425318288 [label="layers.0.2.bn.weight
 (64)" fillcolor=lightblue]
	47701425318288 -> 47700274737456
	47700274737456 [label=AccumulateGrad]
	47700274736928 -> 47700274737408
	47701425318384 [label="layers.0.2.bn.bias
 (64)" fillcolor=lightblue]
	47701425318384 -> 47700274736928
	47700274736928 [label=AccumulateGrad]
	47700274737312 -> 47700274737216
	47700274737312 [label=ReluBackward0]
	47700274737648 -> 47700274737312
	47700274737648 [label=CudnnBatchNormBackward0]
	47700274737840 -> 47700274737648
	47700274737840 [label=ConvolutionBackward0]
	47700274736112 -> 47700274737840
	47700274737696 -> 47700274737840
	47700274737456 -> 47700274737648
	47700274736928 -> 47700274737648
	47700274736784 -> 47700274736736
	47701425314832 [label="layers.0.2.fc.1.weight
 (64, 128, 1)" fillcolor=lightblue]
	47701425314832 -> 47700274736784
	47700274736784 [label=AccumulateGrad]
	47700274736640 -> 47700274736736
	47701425314928 [label="layers.0.2.fc.1.bias
 (64)" fillcolor=lightblue]
	47701425314928 -> 47700274736640
	47700274736640 [label=AccumulateGrad]
	47700274736544 -> 47700274736448
	47700274736400 -> 47700274736304
	47700274736400 [label=MulBackward0]
	47700274736880 -> 47700274736400
	47700274736880 [label=RsubBackward1]
	47700274736592 -> 47700274736880
	47700274737312 -> 47700274736400
	47700274736256 -> 47700274736160
	47700274736256 [label=ExpandBackward0]
	47700274737072 -> 47700274736256
	47700274737072 [label=ViewBackward0]
	47700274736496 -> 47700274737072
	47700274736496 [label=SigmoidBackward0]
	47700274737264 -> 47700274736496
	47700274737264 [label=MmBackward0]
	47700274738320 -> 47700274737264
	47700274738320 [label=ReluBackward0]
	47700274737360 -> 47700274738320
	47700274737360 [label=MmBackward0]
	47700274737984 -> 47700274737360
	47700274737984 [label=ViewBackward0]
	47700274739232 -> 47700274737984
	47700274739232 [label=SqueezeBackward1]
	47700274676592 -> 47700274739232
	47700274676592 [label=MeanBackward1]
	47700274676784 -> 47700274676592
	47700274676784 [label=UnsqueezeBackward0]
	47700274736304 -> 47700274676784
	47700274738800 -> 47700274737360
	47700274738800 [label=TBackward0]
	47700274676352 -> 47700274738800
	47701425314640 [label="layers.0.2.se.fc.0.weight
 (4, 64)" fillcolor=lightblue]
	47701425314640 -> 47700274676352
	47700274676352 [label=AccumulateGrad]
	47700274737552 -> 47700274737264
	47700274737552 [label=TBackward0]
	47700274738608 -> 47700274737552
	47701425315024 [label="layers.0.2.se.fc.2.weight
 (64, 4)" fillcolor=lightblue]
	47701425315024 -> 47700274738608
	47700274738608 [label=AccumulateGrad]
	47700274736112 -> 47700274736016
	47700274735968 -> 47700274735824
	47701425319056 [label="layers.1.0.conv1.weight
 (128, 64, 7)" fillcolor=lightblue]
	47701425319056 -> 47700274735968
	47700274735968 [label=AccumulateGrad]
	47700274735776 -> 47700274735728
	47701425319152 [label="layers.1.0.bn.weight
 (128)" fillcolor=lightblue]
	47701425319152 -> 47700274735776
	47700274735776 [label=AccumulateGrad]
	47700274735248 -> 47700274735728
	47701425319248 [label="layers.1.0.bn.bias
 (128)" fillcolor=lightblue]
	47701425319248 -> 47700274735248
	47700274735248 [label=AccumulateGrad]
	47700274735632 -> 47700274735536
	47700274735632 [label=ReluBackward0]
	47700274735920 -> 47700274735632
	47700274735920 [label=CudnnBatchNormBackward0]
	47700274736208 -> 47700274735920
	47700274736208 [label=ConvolutionBackward0]
	47700274736016 -> 47700274736208
	47700274735968 -> 47700274736208
	47700274735776 -> 47700274735920
	47700274735248 -> 47700274735920
	47700274735104 -> 47700274735056
	47701425319920 [label="layers.1.0.fc.1.weight
 (128, 256, 1)" fillcolor=lightblue]
	47701425319920 -> 47700274735104
	47700274735104 [label=AccumulateGrad]
	47700274734960 -> 47700274735056
	47701425320016 [label="layers.1.0.fc.1.bias
 (128)" fillcolor=lightblue]
	47701425320016 -> 47700274734960
	47700274734960 [label=AccumulateGrad]
	47700274734864 -> 47700274734768
	47700274734720 -> 47700274734624
	47700274734720 [label=MulBackward0]
	47700274735200 -> 47700274734720
	47700274735200 [label=RsubBackward1]
	47700274734912 -> 47700274735200
	47700274735632 -> 47700274734720
	47700274734576 -> 47700274734480
	47700274734576 [label=ExpandBackward0]
	47700274735392 -> 47700274734576
	47700274735392 [label=ViewBackward0]
	47700274734816 -> 47700274735392
	47700274734816 [label=SigmoidBackward0]
	47700274735584 -> 47700274734816
	47700274735584 [label=MmBackward0]
	47700274736688 -> 47700274735584
	47700274736688 [label=ReluBackward0]
	47700274735680 -> 47700274736688
	47700274735680 [label=MmBackward0]
	47700274736352 -> 47700274735680
	47700274736352 [label=ViewBackward0]
	47700274737600 -> 47700274736352
	47700274737600 [label=SqueezeBackward1]
	47700274676688 -> 47700274737600
	47700274676688 [label=MeanBackward1]
	47700274676928 -> 47700274676688
	47700274676928 [label=UnsqueezeBackward0]
	47700274734624 -> 47700274676928
	47700274737168 -> 47700274735680
	47700274737168 [label=TBackward0]
	47700274676736 -> 47700274737168
	47701425319728 [label="layers.1.0.se.fc.0.weight
 (8, 128)" fillcolor=lightblue]
	47701425319728 -> 47700274676736
	47700274676736 [label=AccumulateGrad]
	47700274735872 -> 47700274735584
	47700274735872 [label=TBackward0]
	47700274736976 -> 47700274735872
	47701425319824 [label="layers.1.0.se.fc.2.weight
 (128, 8)" fillcolor=lightblue]
	47701425319824 -> 47700274736976
	47700274736976 [label=AccumulateGrad]
	47700274734432 -> 47700274732800
	47700274734432 [label=CudnnBatchNormBackward0]
	47700274735296 -> 47700274734432
	47700274735296 [label=ConvolutionBackward0]
	47700274736016 -> 47700274735296
	47700274736064 -> 47700274735296
	47701425314736 [label="layers.1.0.downsample.0.weight
 (128, 64, 1)" fillcolor=lightblue]
	47701425314736 -> 47700274736064
	47700274736064 [label=AccumulateGrad]
	47700274735008 -> 47700274734432
	47701425314352 [label="layers.1.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	47701425314352 -> 47700274735008
	47700274735008 [label=AccumulateGrad]
	47700274734528 -> 47700274734432
	47701425318672 [label="layers.1.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	47701425318672 -> 47700274734528
	47700274734528 [label=AccumulateGrad]
	47700274734384 -> 47700274734192
	47701425320112 [label="layers.1.1.conv1.weight
 (128, 128, 7)" fillcolor=lightblue]
	47701425320112 -> 47700274734384
	47700274734384 [label=AccumulateGrad]
	47700274734144 -> 47700274734096
	47701425320208 [label="layers.1.1.bn.weight
 (128)" fillcolor=lightblue]
	47701425320208 -> 47700274734144
	47700274734144 [label=AccumulateGrad]
	47700274733616 -> 47700274734096
	47701425320304 [label="layers.1.1.bn.bias
 (128)" fillcolor=lightblue]
	47701425320304 -> 47700274733616
	47700274733616 [label=AccumulateGrad]
	47700274734000 -> 47700274733904
	47700274734000 [label=ReluBackward0]
	47700274734336 -> 47700274734000
	47700274734336 [label=CudnnBatchNormBackward0]
	47700274735488 -> 47700274734336
	47700274735488 [label=ConvolutionBackward0]
	47700274732800 -> 47700274735488
	47700274734384 -> 47700274735488
	47700274734144 -> 47700274734336
	47700274733616 -> 47700274734336
	47700274733472 -> 47700274733424
	47701425320976 [label="layers.1.1.fc.1.weight
 (128, 256, 1)" fillcolor=lightblue]
	47701425320976 -> 47700274733472
	47700274733472 [label=AccumulateGrad]
	47700274733328 -> 47700274733424
	47701425321072 [label="layers.1.1.fc.1.bias
 (128)" fillcolor=lightblue]
	47701425321072 -> 47700274733328
	47700274733328 [label=AccumulateGrad]
	47700274733232 -> 47700274733136
	47700274733088 -> 47700274732992
	47700274733088 [label=MulBackward0]
	47700274733568 -> 47700274733088
	47700274733568 [label=RsubBackward1]
	47700274733280 -> 47700274733568
	47700274734000 -> 47700274733088
	47700274732944 -> 47700274732848
	47700274732944 [label=ExpandBackward0]
	47700274733760 -> 47700274732944
	47700274733760 [label=ViewBackward0]
	47700274733184 -> 47700274733760
	47700274733184 [label=SigmoidBackward0]
	47700274733952 -> 47700274733184
	47700274733952 [label=MmBackward0]
	47700274734672 -> 47700274733952
	47700274734672 [label=ReluBackward0]
	47700274734048 -> 47700274734672
	47700274734048 [label=MmBackward0]
	47700274677024 -> 47700274734048
	47700274677024 [label=ViewBackward0]
	47700274677072 -> 47700274677024
	47700274677072 [label=SqueezeBackward1]
	47700274677168 -> 47700274677072
	47700274677168 [label=MeanBackward1]
	47700274677264 -> 47700274677168
	47700274677264 [label=UnsqueezeBackward0]
	47700274732992 -> 47700274677264
	47700274676976 -> 47700274734048
	47700274676976 [label=TBackward0]
	47700274677216 -> 47700274676976
	47701425320784 [label="layers.1.1.se.fc.0.weight
 (8, 128)" fillcolor=lightblue]
	47701425320784 -> 47700274677216
	47700274677216 [label=AccumulateGrad]
	47700274734240 -> 47700274733952
	47700274734240 [label=TBackward0]
	47700274734288 -> 47700274734240
	47701425320880 [label="layers.1.1.se.fc.2.weight
 (128, 8)" fillcolor=lightblue]
	47701425320880 -> 47700274734288
	47700274734288 [label=AccumulateGrad]
	47700274732800 -> 47700274731168
	47700274732752 -> 47700274732560
	47701425321168 [label="layers.1.2.conv1.weight
 (128, 128, 7)" fillcolor=lightblue]
	47701425321168 -> 47700274732752
	47700274732752 [label=AccumulateGrad]
	47700274732512 -> 47700274732464
	47701425321264 [label="layers.1.2.bn.weight
 (128)" fillcolor=lightblue]
	47701425321264 -> 47700274732512
	47700274732512 [label=AccumulateGrad]
	47700274731984 -> 47700274732464
	47701425321360 [label="layers.1.2.bn.bias
 (128)" fillcolor=lightblue]
	47701425321360 -> 47700274731984
	47700274731984 [label=AccumulateGrad]
	47700274732368 -> 47700274732272
	47700274732368 [label=ReluBackward0]
	47700274732704 -> 47700274732368
	47700274732704 [label=CudnnBatchNormBackward0]
	47700274732896 -> 47700274732704
	47700274732896 [label=ConvolutionBackward0]
	47700274731168 -> 47700274732896
	47700274732752 -> 47700274732896
	47700274732512 -> 47700274732704
	47700274731984 -> 47700274732704
	47700274731840 -> 47700274731792
	47701425322032 [label="layers.1.2.fc.1.weight
 (128, 256, 1)" fillcolor=lightblue]
	47701425322032 -> 47700274731840
	47700274731840 [label=AccumulateGrad]
	47700274731696 -> 47700274731792
	47701425322128 [label="layers.1.2.fc.1.bias
 (128)" fillcolor=lightblue]
	47701425322128 -> 47700274731696
	47700274731696 [label=AccumulateGrad]
	47700274731600 -> 47700274731504
	47700274731456 -> 47700274731360
	47700274731456 [label=MulBackward0]
	47700274731936 -> 47700274731456
	47700274731936 [label=RsubBackward1]
	47700274731648 -> 47700274731936
	47700274732368 -> 47700274731456
	47700274731312 -> 47700274731216
	47700274731312 [label=ExpandBackward0]
	47700274732128 -> 47700274731312
	47700274732128 [label=ViewBackward0]
	47700274731552 -> 47700274732128
	47700274731552 [label=SigmoidBackward0]
	47700274732320 -> 47700274731552
	47700274732320 [label=MmBackward0]
	47700274733376 -> 47700274732320
	47700274733376 [label=ReluBackward0]
	47700274732416 -> 47700274733376
	47700274732416 [label=MmBackward0]
	47700274733040 -> 47700274732416
	47700274733040 [label=ViewBackward0]
	47700274677312 -> 47700274733040
	47700274677312 [label=SqueezeBackward1]
	47700274676880 -> 47700274677312
	47700274676880 [label=MeanBackward1]
	47700274677408 -> 47700274676880
	47700274677408 [label=UnsqueezeBackward0]
	47700274731360 -> 47700274677408
	47700274733856 -> 47700274732416
	47700274733856 [label=TBackward0]
	47700274676832 -> 47700274733856
	47701425321840 [label="layers.1.2.se.fc.0.weight
 (8, 128)" fillcolor=lightblue]
	47701425321840 -> 47700274676832
	47700274676832 [label=AccumulateGrad]
	47700274732608 -> 47700274732320
	47700274732608 [label=TBackward0]
	47700274733664 -> 47700274732608
	47701425321936 [label="layers.1.2.se.fc.2.weight
 (128, 8)" fillcolor=lightblue]
	47701425321936 -> 47700274733664
	47700274733664 [label=AccumulateGrad]
	47700274731168 -> 47700274729536
	47700274731120 -> 47700274730928
	47701425322224 [label="layers.1.3.conv1.weight
 (128, 128, 7)" fillcolor=lightblue]
	47701425322224 -> 47700274731120
	47700274731120 [label=AccumulateGrad]
	47700274730880 -> 47700274730832
	47701425322320 [label="layers.1.3.bn.weight
 (128)" fillcolor=lightblue]
	47701425322320 -> 47700274730880
	47700274730880 [label=AccumulateGrad]
	47700274730352 -> 47700274730832
	47701425322416 [label="layers.1.3.bn.bias
 (128)" fillcolor=lightblue]
	47701425322416 -> 47700274730352
	47700274730352 [label=AccumulateGrad]
	47700274730736 -> 47700274730640
	47700274730736 [label=ReluBackward0]
	47700274731072 -> 47700274730736
	47700274731072 [label=CudnnBatchNormBackward0]
	47700274731264 -> 47700274731072
	47700274731264 [label=ConvolutionBackward0]
	47700274729536 -> 47700274731264
	47700274731120 -> 47700274731264
	47700274730880 -> 47700274731072
	47700274730352 -> 47700274731072
	47700274730208 -> 47700274730160
	47701425323088 [label="layers.1.3.fc.1.weight
 (128, 256, 1)" fillcolor=lightblue]
	47701425323088 -> 47700274730208
	47700274730208 [label=AccumulateGrad]
	47700274730064 -> 47700274730160
	47701425323184 [label="layers.1.3.fc.1.bias
 (128)" fillcolor=lightblue]
	47701425323184 -> 47700274730064
	47700274730064 [label=AccumulateGrad]
	47700274729968 -> 47700274729872
	47700274729824 -> 47700274729728
	47700274729824 [label=MulBackward0]
	47700274730304 -> 47700274729824
	47700274730304 [label=RsubBackward1]
	47700274730016 -> 47700274730304
	47700274730736 -> 47700274729824
	47700274729680 -> 47700274729584
	47700274729680 [label=ExpandBackward0]
	47700274730496 -> 47700274729680
	47700274730496 [label=ViewBackward0]
	47700274729920 -> 47700274730496
	47700274729920 [label=SigmoidBackward0]
	47700274730688 -> 47700274729920
	47700274730688 [label=MmBackward0]
	47700274731744 -> 47700274730688
	47700274731744 [label=ReluBackward0]
	47700274730784 -> 47700274731744
	47700274730784 [label=MmBackward0]
	47700274731408 -> 47700274730784
	47700274731408 [label=ViewBackward0]
	47700274732656 -> 47700274731408
	47700274732656 [label=SqueezeBackward1]
	47700274677360 -> 47700274732656
	47700274677360 [label=MeanBackward1]
	47700274677552 -> 47700274677360
	47700274677552 [label=UnsqueezeBackward0]
	47700274729728 -> 47700274677552
	47700274732224 -> 47700274730784
	47700274732224 [label=TBackward0]
	47700274677120 -> 47700274732224
	47701425322896 [label="layers.1.3.se.fc.0.weight
 (8, 128)" fillcolor=lightblue]
	47701425322896 -> 47700274677120
	47700274677120 [label=AccumulateGrad]
	47700274730976 -> 47700274730688
	47700274730976 [label=TBackward0]
	47700274732032 -> 47700274730976
	47701425322992 [label="layers.1.3.se.fc.2.weight
 (128, 8)" fillcolor=lightblue]
	47701425322992 -> 47700274732032
	47700274732032 [label=AccumulateGrad]
	47700274729536 -> 47700274729440
	47700274729392 -> 47700274729248
	47701425323856 [label="layers.2.0.conv1.weight
 (256, 128, 7)" fillcolor=lightblue]
	47701425323856 -> 47700274729392
	47700274729392 [label=AccumulateGrad]
	47700274729200 -> 47700274729152
	47701425323952 [label="layers.2.0.bn.weight
 (256)" fillcolor=lightblue]
	47701425323952 -> 47700274729200
	47700274729200 [label=AccumulateGrad]
	47700274728672 -> 47700274729152
	47701425864784 [label="layers.2.0.bn.bias
 (256)" fillcolor=lightblue]
	47701425864784 -> 47700274728672
	47700274728672 [label=AccumulateGrad]
	47700274729056 -> 47700274728960
	47700274729056 [label=ReluBackward0]
	47700274729344 -> 47700274729056
	47700274729344 [label=CudnnBatchNormBackward0]
	47700274729632 -> 47700274729344
	47700274729632 [label=ConvolutionBackward0]
	47700274729440 -> 47700274729632
	47700274729392 -> 47700274729632
	47700274729200 -> 47700274729344
	47700274728672 -> 47700274729344
	47700274728528 -> 47700274728480
	47701425865456 [label="layers.2.0.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425865456 -> 47700274728528
	47700274728528 [label=AccumulateGrad]
	47700274728384 -> 47700274728480
	47701425865552 [label="layers.2.0.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425865552 -> 47700274728384
	47700274728384 [label=AccumulateGrad]
	47700274728288 -> 47700274728192
	47700274728144 -> 47700274728048
	47700274728144 [label=MulBackward0]
	47700274728624 -> 47700274728144
	47700274728624 [label=RsubBackward1]
	47700274728336 -> 47700274728624
	47700274729056 -> 47700274728144
	47700274728000 -> 47700274727904
	47700274728000 [label=ExpandBackward0]
	47700274728816 -> 47700274728000
	47700274728816 [label=ViewBackward0]
	47700274728240 -> 47700274728816
	47700274728240 [label=SigmoidBackward0]
	47700274729008 -> 47700274728240
	47700274729008 [label=MmBackward0]
	47700274730112 -> 47700274729008
	47700274730112 [label=ReluBackward0]
	47700274729104 -> 47700274730112
	47700274729104 [label=MmBackward0]
	47700274729776 -> 47700274729104
	47700274729776 [label=ViewBackward0]
	47700274731024 -> 47700274729776
	47700274731024 [label=SqueezeBackward1]
	47700274677456 -> 47700274731024
	47700274677456 [label=MeanBackward1]
	47700274677696 -> 47700274677456
	47700274677696 [label=UnsqueezeBackward0]
	47700274728048 -> 47700274677696
	47700274730592 -> 47700274729104
	47700274730592 [label=TBackward0]
	47700274677504 -> 47700274730592
	47701425865264 [label="layers.2.0.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425865264 -> 47700274677504
	47700274677504 [label=AccumulateGrad]
	47700274729296 -> 47700274729008
	47700274729296 [label=TBackward0]
	47700274730400 -> 47700274729296
	47701425865360 [label="layers.2.0.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425865360 -> 47700274730400
	47700274730400 [label=AccumulateGrad]
	47700274727856 -> 47700274726224
	47700274727856 [label=CudnnBatchNormBackward0]
	47700274728720 -> 47700274727856
	47700274728720 [label=ConvolutionBackward0]
	47700274729440 -> 47700274728720
	47700274729488 -> 47700274728720
	47701425323280 [label="layers.2.0.downsample.0.weight
 (256, 128, 1)" fillcolor=lightblue]
	47701425323280 -> 47700274729488
	47700274729488 [label=AccumulateGrad]
	47700274728432 -> 47700274727856
	47701425323376 [label="layers.2.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	47701425323376 -> 47700274728432
	47700274728432 [label=AccumulateGrad]
	47700274727952 -> 47700274727856
	47701425323472 [label="layers.2.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	47701425323472 -> 47700274727952
	47700274727952 [label=AccumulateGrad]
	47700274727808 -> 47700274727616
	47701425865648 [label="layers.2.1.conv1.weight
 (256, 256, 7)" fillcolor=lightblue]
	47701425865648 -> 47700274727808
	47700274727808 [label=AccumulateGrad]
	47700274727568 -> 47700274727520
	47701425865744 [label="layers.2.1.bn.weight
 (256)" fillcolor=lightblue]
	47701425865744 -> 47700274727568
	47700274727568 [label=AccumulateGrad]
	47700274727040 -> 47700274727520
	47701425865840 [label="layers.2.1.bn.bias
 (256)" fillcolor=lightblue]
	47701425865840 -> 47700274727040
	47700274727040 [label=AccumulateGrad]
	47700274727424 -> 47700274727328
	47700274727424 [label=ReluBackward0]
	47700274727760 -> 47700274727424
	47700274727760 [label=CudnnBatchNormBackward0]
	47700274728912 -> 47700274727760
	47700274728912 [label=ConvolutionBackward0]
	47700274726224 -> 47700274728912
	47700274727808 -> 47700274728912
	47700274727568 -> 47700274727760
	47700274727040 -> 47700274727760
	47700274726896 -> 47700274726848
	47701425866512 [label="layers.2.1.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425866512 -> 47700274726896
	47700274726896 [label=AccumulateGrad]
	47700274726752 -> 47700274726848
	47701425866608 [label="layers.2.1.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425866608 -> 47700274726752
	47700274726752 [label=AccumulateGrad]
	47700274726656 -> 47700274726560
	47700274726512 -> 47700274726416
	47700274726512 [label=MulBackward0]
	47700274726992 -> 47700274726512
	47700274726992 [label=RsubBackward1]
	47700274726704 -> 47700274726992
	47700274727424 -> 47700274726512
	47700274726368 -> 47700274726272
	47700274726368 [label=ExpandBackward0]
	47700274727184 -> 47700274726368
	47700274727184 [label=ViewBackward0]
	47700274726608 -> 47700274727184
	47700274726608 [label=SigmoidBackward0]
	47700274727376 -> 47700274726608
	47700274727376 [label=MmBackward0]
	47700274728096 -> 47700274727376
	47700274728096 [label=ReluBackward0]
	47700274727472 -> 47700274728096
	47700274727472 [label=MmBackward0]
	47700274677792 -> 47700274727472
	47700274677792 [label=ViewBackward0]
	47700274677840 -> 47700274677792
	47700274677840 [label=SqueezeBackward1]
	47700274677936 -> 47700274677840
	47700274677936 [label=MeanBackward1]
	47700274678032 -> 47700274677936
	47700274678032 [label=UnsqueezeBackward0]
	47700274726416 -> 47700274678032
	47700274677744 -> 47700274727472
	47700274677744 [label=TBackward0]
	47700274677984 -> 47700274677744
	47701425866320 [label="layers.2.1.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425866320 -> 47700274677984
	47700274677984 [label=AccumulateGrad]
	47700274727664 -> 47700274727376
	47700274727664 [label=TBackward0]
	47700274727712 -> 47700274727664
	47701425866416 [label="layers.2.1.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425866416 -> 47700274727712
	47700274727712 [label=AccumulateGrad]
	47700274726224 -> 47701425536688
	47700274726176 -> 47700274725984
	47701425866704 [label="layers.2.2.conv1.weight
 (256, 256, 7)" fillcolor=lightblue]
	47701425866704 -> 47700274726176
	47700274726176 [label=AccumulateGrad]
	47700274725936 -> 47700274725888
	47701425866800 [label="layers.2.2.bn.weight
 (256)" fillcolor=lightblue]
	47701425866800 -> 47700274725936
	47700274725936 [label=AccumulateGrad]
	47700274725408 -> 47700274725888
	47701425866896 [label="layers.2.2.bn.bias
 (256)" fillcolor=lightblue]
	47701425866896 -> 47700274725408
	47700274725408 [label=AccumulateGrad]
	47700274725792 -> 47700274725696
	47700274725792 [label=ReluBackward0]
	47700274726128 -> 47700274725792
	47700274726128 [label=CudnnBatchNormBackward0]
	47700274726320 -> 47700274726128
	47700274726320 [label=ConvolutionBackward0]
	47701425536688 -> 47700274726320
	47700274726176 -> 47700274726320
	47700274725936 -> 47700274726128
	47700274725408 -> 47700274726128
	47700274725264 -> 47700274725216
	47701425867568 [label="layers.2.2.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425867568 -> 47700274725264
	47700274725264 [label=AccumulateGrad]
	47700274725120 -> 47700274725216
	47701425867664 [label="layers.2.2.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425867664 -> 47700274725120
	47700274725120 [label=AccumulateGrad]
	47700274725024 -> 47701425536976
	47701425536928 -> 47701425536880
	47701425536928 [label=MulBackward0]
	47700274725360 -> 47701425536928
	47700274725360 [label=RsubBackward1]
	47700274725072 -> 47700274725360
	47700274725792 -> 47701425536928
	47701425536832 -> 47701425536736
	47701425536832 [label=ExpandBackward0]
	47700274725552 -> 47701425536832
	47700274725552 [label=ViewBackward0]
	47700274724976 -> 47700274725552
	47700274724976 [label=SigmoidBackward0]
	47700274725744 -> 47700274724976
	47700274725744 [label=MmBackward0]
	47700274726800 -> 47700274725744
	47700274726800 [label=ReluBackward0]
	47700274725840 -> 47700274726800
	47700274725840 [label=MmBackward0]
	47700274726464 -> 47700274725840
	47700274726464 [label=ViewBackward0]
	47700274678080 -> 47700274726464
	47700274678080 [label=SqueezeBackward1]
	47700274677648 -> 47700274678080
	47700274677648 [label=MeanBackward1]
	47700274678176 -> 47700274677648
	47700274678176 [label=UnsqueezeBackward0]
	47701425536880 -> 47700274678176
	47700274727280 -> 47700274725840
	47700274727280 [label=TBackward0]
	47700274677600 -> 47700274727280
	47701425867376 [label="layers.2.2.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425867376 -> 47700274677600
	47700274677600 [label=AccumulateGrad]
	47700274726032 -> 47700274725744
	47700274726032 [label=TBackward0]
	47700274727088 -> 47700274726032
	47701425867472 [label="layers.2.2.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425867472 -> 47700274727088
	47700274727088 [label=AccumulateGrad]
	47701425536688 -> 47701425535056
	47701425536640 -> 47701425536448
	47701425867760 [label="layers.2.3.conv1.weight
 (256, 256, 7)" fillcolor=lightblue]
	47701425867760 -> 47701425536640
	47701425536640 [label=AccumulateGrad]
	47701425536400 -> 47701425536352
	47701425867856 [label="layers.2.3.bn.weight
 (256)" fillcolor=lightblue]
	47701425867856 -> 47701425536400
	47701425536400 [label=AccumulateGrad]
	47701425535872 -> 47701425536352
	47701425867952 [label="layers.2.3.bn.bias
 (256)" fillcolor=lightblue]
	47701425867952 -> 47701425535872
	47701425535872 [label=AccumulateGrad]
	47701425536256 -> 47701425536160
	47701425536256 [label=ReluBackward0]
	47701425536592 -> 47701425536256
	47701425536592 [label=CudnnBatchNormBackward0]
	47701425536544 -> 47701425536592
	47701425536544 [label=ConvolutionBackward0]
	47701425535056 -> 47701425536544
	47701425536640 -> 47701425536544
	47701425536400 -> 47701425536592
	47701425535872 -> 47701425536592
	47701425535728 -> 47701425535680
	47701425868624 [label="layers.2.3.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425868624 -> 47701425535728
	47701425535728 [label=AccumulateGrad]
	47701425535584 -> 47701425535680
	47701425868720 [label="layers.2.3.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425868720 -> 47701425535584
	47701425535584 [label=AccumulateGrad]
	47701425535488 -> 47701425535392
	47701425535344 -> 47701425535248
	47701425535344 [label=MulBackward0]
	47701425535824 -> 47701425535344
	47701425535824 [label=RsubBackward1]
	47701425535536 -> 47701425535824
	47701425536256 -> 47701425535344
	47701425535200 -> 47701425535104
	47701425535200 [label=ExpandBackward0]
	47701425536016 -> 47701425535200
	47701425536016 [label=ViewBackward0]
	47701425535440 -> 47701425536016
	47701425535440 [label=SigmoidBackward0]
	47701425536208 -> 47701425535440
	47701425536208 [label=MmBackward0]
	47701425536784 -> 47701425536208
	47701425536784 [label=ReluBackward0]
	47701425536304 -> 47701425536784
	47701425536304 [label=MmBackward0]
	47700274724928 -> 47701425536304
	47700274724928 [label=ViewBackward0]
	47700274726080 -> 47700274724928
	47700274726080 [label=SqueezeBackward1]
	47700274678128 -> 47700274726080
	47700274678128 [label=MeanBackward1]
	47700274678320 -> 47700274678128
	47700274678320 [label=UnsqueezeBackward0]
	47701425535248 -> 47700274678320
	47700274725648 -> 47701425536304
	47700274725648 [label=TBackward0]
	47700274677888 -> 47700274725648
	47701425868432 [label="layers.2.3.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425868432 -> 47700274677888
	47700274677888 [label=AccumulateGrad]
	47701425536496 -> 47701425536208
	47701425536496 [label=TBackward0]
	47700274725456 -> 47701425536496
	47701425868528 [label="layers.2.3.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425868528 -> 47700274725456
	47700274725456 [label=AccumulateGrad]
	47701425535056 -> 47701425533424
	47701425535008 -> 47701425534816
	47701425868816 [label="layers.2.4.conv1.weight
 (256, 256, 7)" fillcolor=lightblue]
	47701425868816 -> 47701425535008
	47701425535008 [label=AccumulateGrad]
	47701425534768 -> 47701425534720
	47701425868912 [label="layers.2.4.bn.weight
 (256)" fillcolor=lightblue]
	47701425868912 -> 47701425534768
	47701425534768 [label=AccumulateGrad]
	47701425534240 -> 47701425534720
	47701425869008 [label="layers.2.4.bn.bias
 (256)" fillcolor=lightblue]
	47701425869008 -> 47701425534240
	47701425534240 [label=AccumulateGrad]
	47701425534624 -> 47701425534528
	47701425534624 [label=ReluBackward0]
	47701425534960 -> 47701425534624
	47701425534960 [label=CudnnBatchNormBackward0]
	47701425535152 -> 47701425534960
	47701425535152 [label=ConvolutionBackward0]
	47701425533424 -> 47701425535152
	47701425535008 -> 47701425535152
	47701425534768 -> 47701425534960
	47701425534240 -> 47701425534960
	47701425534096 -> 47701425534048
	47701425869680 [label="layers.2.4.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425869680 -> 47701425534096
	47701425534096 [label=AccumulateGrad]
	47701425533952 -> 47701425534048
	47701425869776 [label="layers.2.4.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425869776 -> 47701425533952
	47701425533952 [label=AccumulateGrad]
	47701425533856 -> 47701425533760
	47701425533712 -> 47701425533616
	47701425533712 [label=MulBackward0]
	47701425534192 -> 47701425533712
	47701425534192 [label=RsubBackward1]
	47701425533904 -> 47701425534192
	47701425534624 -> 47701425533712
	47701425533568 -> 47701425533472
	47701425533568 [label=ExpandBackward0]
	47701425534384 -> 47701425533568
	47701425534384 [label=ViewBackward0]
	47701425533808 -> 47701425534384
	47701425533808 [label=SigmoidBackward0]
	47701425534576 -> 47701425533808
	47701425534576 [label=MmBackward0]
	47701425535632 -> 47701425534576
	47701425535632 [label=ReluBackward0]
	47701425534672 -> 47701425535632
	47701425534672 [label=MmBackward0]
	47701425535296 -> 47701425534672
	47701425535296 [label=ViewBackward0]
	47700274725168 -> 47701425535296
	47700274725168 [label=SqueezeBackward1]
	47700274678224 -> 47700274725168
	47700274678224 [label=MeanBackward1]
	47700274678464 -> 47700274678224
	47700274678464 [label=UnsqueezeBackward0]
	47701425533616 -> 47700274678464
	47701425536112 -> 47701425534672
	47701425536112 [label=TBackward0]
	47700274678272 -> 47701425536112
	47701425869488 [label="layers.2.4.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425869488 -> 47700274678272
	47700274678272 [label=AccumulateGrad]
	47701425534864 -> 47701425534576
	47701425534864 [label=TBackward0]
	47701425535920 -> 47701425534864
	47701425869584 [label="layers.2.4.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425869584 -> 47701425535920
	47701425535920 [label=AccumulateGrad]
	47701425533424 -> 47701425531792
	47701425533376 -> 47701425533184
	47701425869872 [label="layers.2.5.conv1.weight
 (256, 256, 7)" fillcolor=lightblue]
	47701425869872 -> 47701425533376
	47701425533376 [label=AccumulateGrad]
	47701425533136 -> 47701425533088
	47701425869968 [label="layers.2.5.bn.weight
 (256)" fillcolor=lightblue]
	47701425869968 -> 47701425533136
	47701425533136 [label=AccumulateGrad]
	47701425532608 -> 47701425533088
	47701425870064 [label="layers.2.5.bn.bias
 (256)" fillcolor=lightblue]
	47701425870064 -> 47701425532608
	47701425532608 [label=AccumulateGrad]
	47701425532992 -> 47701425532896
	47701425532992 [label=ReluBackward0]
	47701425533328 -> 47701425532992
	47701425533328 [label=CudnnBatchNormBackward0]
	47701425533520 -> 47701425533328
	47701425533520 [label=ConvolutionBackward0]
	47701425531792 -> 47701425533520
	47701425533376 -> 47701425533520
	47701425533136 -> 47701425533328
	47701425532608 -> 47701425533328
	47701425532464 -> 47701425532416
	47701425870736 [label="layers.2.5.fc.1.weight
 (256, 512, 1)" fillcolor=lightblue]
	47701425870736 -> 47701425532464
	47701425532464 [label=AccumulateGrad]
	47701425532320 -> 47701425532416
	47701425870832 [label="layers.2.5.fc.1.bias
 (256)" fillcolor=lightblue]
	47701425870832 -> 47701425532320
	47701425532320 [label=AccumulateGrad]
	47701425532224 -> 47701425532128
	47701425532080 -> 47701425531984
	47701425532080 [label=MulBackward0]
	47701425532560 -> 47701425532080
	47701425532560 [label=RsubBackward1]
	47701425532272 -> 47701425532560
	47701425532992 -> 47701425532080
	47701425531936 -> 47701425531840
	47701425531936 [label=ExpandBackward0]
	47701425532752 -> 47701425531936
	47701425532752 [label=ViewBackward0]
	47701425532176 -> 47701425532752
	47701425532176 [label=SigmoidBackward0]
	47701425532944 -> 47701425532176
	47701425532944 [label=MmBackward0]
	47701425534000 -> 47701425532944
	47701425534000 [label=ReluBackward0]
	47701425533040 -> 47701425534000
	47701425533040 [label=MmBackward0]
	47701425533664 -> 47701425533040
	47701425533664 [label=ViewBackward0]
	47701425534912 -> 47701425533664
	47701425534912 [label=SqueezeBackward1]
	47700274678368 -> 47701425534912
	47700274678368 [label=MeanBackward1]
	47700274678608 -> 47700274678368
	47700274678608 [label=UnsqueezeBackward0]
	47701425531984 -> 47700274678608
	47701425534480 -> 47701425533040
	47701425534480 [label=TBackward0]
	47700274678416 -> 47701425534480
	47701425870544 [label="layers.2.5.se.fc.0.weight
 (16, 256)" fillcolor=lightblue]
	47701425870544 -> 47700274678416
	47700274678416 [label=AccumulateGrad]
	47701425533232 -> 47701425532944
	47701425533232 [label=TBackward0]
	47701425534288 -> 47701425533232
	47701425870640 [label="layers.2.5.se.fc.2.weight
 (256, 16)" fillcolor=lightblue]
	47701425870640 -> 47701425534288
	47701425534288 [label=AccumulateGrad]
	47701425531792 -> 47701425531696
	47701425531648 -> 47701425531504
	47701425871504 [label="layers.3.0.conv1.weight
 (512, 256, 7)" fillcolor=lightblue]
	47701425871504 -> 47701425531648
	47701425531648 [label=AccumulateGrad]
	47701425531456 -> 47701425531408
	47701425871600 [label="layers.3.0.bn.weight
 (512)" fillcolor=lightblue]
	47701425871600 -> 47701425531456
	47701425531456 [label=AccumulateGrad]
	47701425530928 -> 47701425531408
	47701425871696 [label="layers.3.0.bn.bias
 (512)" fillcolor=lightblue]
	47701425871696 -> 47701425530928
	47701425530928 [label=AccumulateGrad]
	47701425531312 -> 47701425531216
	47701425531312 [label=ReluBackward0]
	47701425531600 -> 47701425531312
	47701425531600 [label=CudnnBatchNormBackward0]
	47701425531888 -> 47701425531600
	47701425531888 [label=ConvolutionBackward0]
	47701425531696 -> 47701425531888
	47701425531648 -> 47701425531888
	47701425531456 -> 47701425531600
	47701425530928 -> 47701425531600
	47701425530784 -> 47701425530736
	47701425872368 [label="layers.3.0.fc.1.weight
 (512, 1024, 1)" fillcolor=lightblue]
	47701425872368 -> 47701425530784
	47701425530784 [label=AccumulateGrad]
	47701425530640 -> 47701425530736
	47701425872464 [label="layers.3.0.fc.1.bias
 (512)" fillcolor=lightblue]
	47701425872464 -> 47701425530640
	47701425530640 [label=AccumulateGrad]
	47701425530544 -> 47701425530448
	47701425530400 -> 47701425530304
	47701425530400 [label=MulBackward0]
	47701425530880 -> 47701425530400
	47701425530880 [label=RsubBackward1]
	47701425530592 -> 47701425530880
	47701425531312 -> 47701425530400
	47701425530256 -> 47701425530160
	47701425530256 [label=ExpandBackward0]
	47701425531072 -> 47701425530256
	47701425531072 [label=ViewBackward0]
	47701425530496 -> 47701425531072
	47701425530496 [label=SigmoidBackward0]
	47701425531264 -> 47701425530496
	47701425531264 [label=MmBackward0]
	47701425532368 -> 47701425531264
	47701425532368 [label=ReluBackward0]
	47701425531360 -> 47701425532368
	47701425531360 [label=MmBackward0]
	47701425532032 -> 47701425531360
	47701425532032 [label=ViewBackward0]
	47701425533280 -> 47701425532032
	47701425533280 [label=SqueezeBackward1]
	47700274678512 -> 47701425533280
	47700274678512 [label=MeanBackward1]
	47700274678752 -> 47700274678512
	47700274678752 [label=UnsqueezeBackward0]
	47701425530304 -> 47700274678752
	47701425532848 -> 47701425531360
	47701425532848 [label=TBackward0]
	47700274678560 -> 47701425532848
	47701425872176 [label="layers.3.0.se.fc.0.weight
 (32, 512)" fillcolor=lightblue]
	47701425872176 -> 47700274678560
	47700274678560 [label=AccumulateGrad]
	47701425531552 -> 47701425531264
	47701425531552 [label=TBackward0]
	47701425532656 -> 47701425531552
	47701425872272 [label="layers.3.0.se.fc.2.weight
 (512, 32)" fillcolor=lightblue]
	47701425872272 -> 47701425532656
	47701425532656 [label=AccumulateGrad]
	47701425530112 -> 47701425528480
	47701425530112 [label=CudnnBatchNormBackward0]
	47701425530976 -> 47701425530112
	47701425530976 [label=ConvolutionBackward0]
	47701425531696 -> 47701425530976
	47701425531744 -> 47701425530976
	47701425870928 [label="layers.3.0.downsample.0.weight
 (512, 256, 1)" fillcolor=lightblue]
	47701425870928 -> 47701425531744
	47701425531744 [label=AccumulateGrad]
	47701425530688 -> 47701425530112
	47701425871024 [label="layers.3.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	47701425871024 -> 47701425530688
	47701425530688 [label=AccumulateGrad]
	47701425530208 -> 47701425530112
	47701425871120 [label="layers.3.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	47701425871120 -> 47701425530208
	47701425530208 [label=AccumulateGrad]
	47701425530064 -> 47701425529872
	47701425872560 [label="layers.3.1.conv1.weight
 (512, 512, 7)" fillcolor=lightblue]
	47701425872560 -> 47701425530064
	47701425530064 [label=AccumulateGrad]
	47701425529824 -> 47701425529776
	47701425872656 [label="layers.3.1.bn.weight
 (512)" fillcolor=lightblue]
	47701425872656 -> 47701425529824
	47701425529824 [label=AccumulateGrad]
	47701425529296 -> 47701425529776
	47701425872752 [label="layers.3.1.bn.bias
 (512)" fillcolor=lightblue]
	47701425872752 -> 47701425529296
	47701425529296 [label=AccumulateGrad]
	47701425529680 -> 47701425529584
	47701425529680 [label=ReluBackward0]
	47701425530016 -> 47701425529680
	47701425530016 [label=CudnnBatchNormBackward0]
	47701425531168 -> 47701425530016
	47701425531168 [label=ConvolutionBackward0]
	47701425528480 -> 47701425531168
	47701425530064 -> 47701425531168
	47701425529824 -> 47701425530016
	47701425529296 -> 47701425530016
	47701425529152 -> 47701425529104
	47701425873424 [label="layers.3.1.fc.1.weight
 (512, 1024, 1)" fillcolor=lightblue]
	47701425873424 -> 47701425529152
	47701425529152 [label=AccumulateGrad]
	47701425529008 -> 47701425529104
	47701425873520 [label="layers.3.1.fc.1.bias
 (512)" fillcolor=lightblue]
	47701425873520 -> 47701425529008
	47701425529008 [label=AccumulateGrad]
	47701425528912 -> 47701425528816
	47701425528768 -> 47701425528672
	47701425528768 [label=MulBackward0]
	47701425529248 -> 47701425528768
	47701425529248 [label=RsubBackward1]
	47701425528960 -> 47701425529248
	47701425529680 -> 47701425528768
	47701425528624 -> 47701425528528
	47701425528624 [label=ExpandBackward0]
	47701425529440 -> 47701425528624
	47701425529440 [label=ViewBackward0]
	47701425528864 -> 47701425529440
	47701425528864 [label=SigmoidBackward0]
	47701425529632 -> 47701425528864
	47701425529632 [label=MmBackward0]
	47701425530352 -> 47701425529632
	47701425530352 [label=ReluBackward0]
	47701425529728 -> 47701425530352
	47701425529728 [label=MmBackward0]
	47700274678848 -> 47701425529728
	47700274678848 [label=ViewBackward0]
	47700274678896 -> 47700274678848
	47700274678896 [label=SqueezeBackward1]
	47700274678992 -> 47700274678896
	47700274678992 [label=MeanBackward1]
	47700274679088 -> 47700274678992
	47700274679088 [label=UnsqueezeBackward0]
	47701425528672 -> 47700274679088
	47700274678800 -> 47701425529728
	47700274678800 [label=TBackward0]
	47700274679040 -> 47700274678800
	47701425873232 [label="layers.3.1.se.fc.0.weight
 (32, 512)" fillcolor=lightblue]
	47701425873232 -> 47700274679040
	47700274679040 [label=AccumulateGrad]
	47701425529920 -> 47701425529632
	47701425529920 [label=TBackward0]
	47701425529968 -> 47701425529920
	47701425873328 [label="layers.3.1.se.fc.2.weight
 (512, 32)" fillcolor=lightblue]
	47701425873328 -> 47701425529968
	47701425529968 [label=AccumulateGrad]
	47701425528480 -> 47701425526848
	47701425528432 -> 47701425528240
	47701425873616 [label="layers.3.2.conv1.weight
 (512, 512, 7)" fillcolor=lightblue]
	47701425873616 -> 47701425528432
	47701425528432 [label=AccumulateGrad]
	47701425528192 -> 47701425528144
	47701425873712 [label="layers.3.2.bn.weight
 (512)" fillcolor=lightblue]
	47701425873712 -> 47701425528192
	47701425528192 [label=AccumulateGrad]
	47701425527664 -> 47701425528144
	47701425873808 [label="layers.3.2.bn.bias
 (512)" fillcolor=lightblue]
	47701425873808 -> 47701425527664
	47701425527664 [label=AccumulateGrad]
	47701425528048 -> 47701425527952
	47701425528048 [label=ReluBackward0]
	47701425528384 -> 47701425528048
	47701425528384 [label=CudnnBatchNormBackward0]
	47701425528576 -> 47701425528384
	47701425528576 [label=ConvolutionBackward0]
	47701425526848 -> 47701425528576
	47701425528432 -> 47701425528576
	47701425528192 -> 47701425528384
	47701425527664 -> 47701425528384
	47701425527520 -> 47701425527472
	47701425874480 [label="layers.3.2.fc.1.weight
 (512, 1024, 1)" fillcolor=lightblue]
	47701425874480 -> 47701425527520
	47701425527520 [label=AccumulateGrad]
	47701425527376 -> 47701425527472
	47701425874576 [label="layers.3.2.fc.1.bias
 (512)" fillcolor=lightblue]
	47701425874576 -> 47701425527376
	47701425527376 [label=AccumulateGrad]
	47701425527280 -> 47701425527184
	47701425527136 -> 47701425527040
	47701425527136 [label=MulBackward0]
	47701425527616 -> 47701425527136
	47701425527616 [label=RsubBackward1]
	47701425527328 -> 47701425527616
	47701425528048 -> 47701425527136
	47701425526992 -> 47701425526896
	47701425526992 [label=ExpandBackward0]
	47701425527808 -> 47701425526992
	47701425527808 [label=ViewBackward0]
	47701425527232 -> 47701425527808
	47701425527232 [label=SigmoidBackward0]
	47701425528000 -> 47701425527232
	47701425528000 [label=MmBackward0]
	47701425529056 -> 47701425528000
	47701425529056 [label=ReluBackward0]
	47701425528096 -> 47701425529056
	47701425528096 [label=MmBackward0]
	47701425528720 -> 47701425528096
	47701425528720 [label=ViewBackward0]
	47700274679136 -> 47701425528720
	47700274679136 [label=SqueezeBackward1]
	47700274678704 -> 47700274679136
	47700274678704 [label=MeanBackward1]
	47700274679232 -> 47700274678704
	47700274679232 [label=UnsqueezeBackward0]
	47701425527040 -> 47700274679232
	47701425529536 -> 47701425528096
	47701425529536 [label=TBackward0]
	47700274678656 -> 47701425529536
	47701425874288 [label="layers.3.2.se.fc.0.weight
 (32, 512)" fillcolor=lightblue]
	47701425874288 -> 47700274678656
	47700274678656 [label=AccumulateGrad]
	47701425528288 -> 47701425528000
	47701425528288 [label=TBackward0]
	47701425529344 -> 47701425528288
	47701425874384 [label="layers.3.2.se.fc.2.weight
 (512, 32)" fillcolor=lightblue]
	47701425874384 -> 47701425529344
	47701425529344 [label=AccumulateGrad]
	47701425526848 -> 47701425526800
	47701425526128 -> 47700274436400
	47701425526128 [label=TBackward0]
	47701425526560 -> 47701425526128
	47701425874960 [label="fc.weight
 (24, 522)" fillcolor=lightblue]
	47701425874960 -> 47701425526560
	47701425526560 [label=AccumulateGrad]
	47700274436400 -> 47700274645520
}
